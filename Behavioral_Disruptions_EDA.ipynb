{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Data Mining Project: Predicting Student Behavioral Disruptions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Library Requirements\n",
    "Install the required libraries specified in the `requirements.txt` file. You can do this using pip:\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "\n",
    "## Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Data Loading and Initial Exploration](#data-loading)\n",
    "3. [Exploratory Data Analysis (EDA)](#eda)\n",
    "4. [Hypothesis Testing](#hypothesis-testing)\n",
    "5. [Feature Engineering](#feature-engineering)\n",
    "6. [Model Development](#model-development)\n",
    "7. [Model Evaluation and Interpretation](#model-evaluation)\n",
    "8. [Result Cleanup](#result-cleanup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "This notebook documents our team's effort to predict and analyze student behavioral disruptions to minimize in-class interruptions.\n",
    "\n",
    "**Team Members:**  \n",
    "**Customer:** Adam West\n",
    "\n",
    "**Objectives:**\n",
    "- Predict behavioral disruptions\n",
    "- Identify anomalous patterns\n",
    "- Provide clear interpretations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import f_oneway, ttest_ind, spearmanr, pearsonr\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, mean_squared_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import root_mean_squared_error  # Import the new function\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, r2_score, mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load datasets\n",
    "bus_conduct = pd.read_csv('TTU Data - Bus Conduct.csv')\n",
    "bus_conduct_updated = pd.read_csv('TTU Data Update - Bus Conduct.csv')\n",
    "family_engagement = pd.read_csv('TTU Data - Family Engagement.csv')\n",
    "disciplinary_referral = pd.read_csv('TTU Data - Disciplinary Referral.csv')\n",
    "disciplinary_referral_updated = pd.read_csv('TTU Data Update - Disciplinary Referral.csv')\n",
    "weather_df = pd.read_csv('weather.csv')\n",
    "\n",
    "# Display the first few rows of each dataset for inspection\n",
    "print(\"Bus Conduct Dataset:\")\n",
    "display(bus_conduct.head())\n",
    "print(\"Bus Conduct Updated Dataset:\")\n",
    "display(bus_conduct_updated.head())\n",
    "\n",
    "print(\"Family Engagement Dataset:\")\n",
    "display(family_engagement.head())\n",
    "\n",
    "print(\"Disciplinary Referral Dataset:\")\n",
    "display(disciplinary_referral.head())\n",
    "\n",
    "print(\"Disciplinary Referral Updated Dataset:\")\n",
    "display(disciplinary_referral_updated.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Combine and clean datasets\n",
    "disciplinary_referral_all = pd.concat([disciplinary_referral, disciplinary_referral_updated], ignore_index=True).drop_duplicates()\n",
    "bus_conduct_all = pd.concat([bus_conduct, bus_conduct_updated], ignore_index=True).drop_duplicates()\n",
    "# Convert date columns to datetime format\n",
    "disciplinary_referral_all['Date of Incident'] = pd.to_datetime(disciplinary_referral_all['Date of Incident'], errors='coerce')\n",
    "bus_conduct_all['Date of Incident'] = pd.to_datetime(bus_conduct_all['Date of Incident'], errors='coerce')\n",
    "# Save combined datasets to CSV files\n",
    "disciplinary_referral_all.to_csv(\"combined_disciplinary_referrals.csv\", index=False)\n",
    "bus_conduct_all.to_csv(\"combined_bus_conduct.csv\", index=False)\n",
    "# Check for missing values in the combined datasets\n",
    "print(\"Missing values in Combined Bus Conduct Data:\")\n",
    "print(bus_conduct_all.isnull().sum())\n",
    "print(\"\\nMissing values in Combined Disciplinary Referral Data:\")\n",
    "print(disciplinary_referral_all.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a 'Month' column for monthly analysis\n",
    "disciplinary_referral_all['Month'] = disciplinary_referral_all['Date of Incident'].dt.month\n",
    "\n",
    "# Group by month and count referrals\n",
    "monthly_referrals = disciplinary_referral_all.groupby('Month').size()\n",
    "\n",
    "# Plot monthly referral counts\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=monthly_referrals.index, y=monthly_referrals.values)\n",
    "plt.title('Monthly Disciplinary Referrals (Updated Dataset)')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Referrals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Identify the top 10 students with the most referrals\n",
    "frequent_students = disciplinary_referral_all['Student Identifier'].value_counts().head(10)\n",
    "\n",
    "# Plot the top 10 students by referral count\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(y=frequent_students.index, x=frequent_students.values, orient='h')\n",
    "plt.title('Top 10 Students by Number of Referrals (Updated Dataset)')\n",
    "plt.xlabel('Number of Referrals')\n",
    "plt.ylabel('Student Identifier')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to categorize time of day\n",
    "def categorize_time(time_str):\n",
    "    if pd.isna(time_str): return \"Unknown\"\n",
    "    time_str = time_str.lower().strip()\n",
    "    if \"before school\" in time_str: return \"Before School\"\n",
    "    elif any(t in time_str for t in [\"8:00am\", \"9:00am\", \"10:00am\", \"11:00am\"]): return \"Morning\"\n",
    "    elif any(t in time_str for t in [\"12:00pm\", \"1:00pm\"]): return \"Early Afternoon\"\n",
    "    elif any(t in time_str for t in [\"2:00pm\", \"3:00pm\"]): return \"Late Afternoon\"\n",
    "    elif \"after school\" in time_str: return \"After School\"\n",
    "    else: return \"Other\"\n",
    "\n",
    "# Define the order of time categories\n",
    "time_order = [\"Before School\", \"Morning\", \"Early Afternoon\", \"Late Afternoon\", \"After School\", \"Other\"]\n",
    "\n",
    "# Apply time categorization to the dataset\n",
    "disciplinary_referral_all[\"Time_Category\"] = disciplinary_referral_all[\"Time of the Day the behavior occurred?\"].apply(categorize_time)\n",
    "\n",
    "# Set ordered categories for plotting\n",
    "disciplinary_referral_all[\"Time_Category\"] = pd.Categorical(\n",
    "    disciplinary_referral_all[\"Time_Category\"],\n",
    "    categories=time_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Group data by grade level and time category\n",
    "grouped = disciplinary_referral_all.groupby([\"Grade_Level\", \"Time_Category\"]).size().unstack().fillna(0)\n",
    "\n",
    "# Sort grades for display\n",
    "grouped = grouped.sort_index()\n",
    "\n",
    "# Plot a heatmap of referrals by grade level and time of day\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(grouped, annot=True, fmt='d', cmap=\"YlGnBu\")\n",
    "plt.title(\"Disciplinary Referrals by Grade Level and Time of Day (Cleaned)\")\n",
    "plt.xlabel(\"Time of Day\")\n",
    "plt.ylabel(\"Grade Level\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert weather data datetime column to datetime format\n",
    "weather_df['datetime'] = pd.to_datetime(weather_df['datetime'], errors='coerce')\n",
    "\n",
    "# Group referrals by date and count\n",
    "referrals_per_day = disciplinary_referral_all.groupby('Date of Incident').size().reset_index(name='referral_count')\n",
    "\n",
    "# Merge referral counts with weather data\n",
    "merged_df = pd.merge(referrals_per_day, weather_df, how='inner', left_on='Date of Incident', right_on='datetime')\n",
    "merged_df.drop(columns=['datetime'], inplace=True)\n",
    "\n",
    "# Categorize temperature into bins\n",
    "bins = [0, 50, 70, 100]\n",
    "labels = ['Cold (<50°F)', 'Mild (50–70°F)', 'Hot (>70°F)']\n",
    "merged_df['Temp_Category'] = pd.cut(merged_df['temp'], bins=bins, labels=labels)\n",
    "\n",
    "# Calculate average referrals by temperature category\n",
    "binned_referrals = merged_df.groupby('Temp_Category')['referral_count'].mean().reset_index()\n",
    "\n",
    "# Plot average referrals by temperature category\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=binned_referrals, x='Temp_Category', y='referral_count', palette='coolwarm')\n",
    "plt.title('Average Referrals by Temperature (Updated)')\n",
    "plt.ylabel('Average Number of Referrals')\n",
    "plt.xlabel('Temperature Range')\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 3.5 Expanded EDA: Additional Insights and Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Expanded EDA: Additional Insights and Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Referrals by School or Staff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze referrals by school or staff\n",
    "staff_referral_counts = disciplinary_referral_all['Please select your school'].value_counts().head(10)\n",
    "\n",
    "# Plot the top 10 schools by referral count\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(y=staff_referral_counts.index, x=staff_referral_counts.values, orient='h')\n",
    "plt.title(\"Top 10 Schools by Referral Count\")\n",
    "plt.xlabel(\"Referrals Issued\")\n",
    "plt.ylabel(\"School\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Weather and Referral Type (e.g Fighting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze weather and referral type (e.g., fighting-related referrals)\n",
    "fighting_referrals = disciplinary_referral_all[\n",
    "    disciplinary_referral_all['Select the Major Referral'].str.contains('fight', na=False, case=False)\n",
    "]\n",
    "\n",
    "# Group fighting-related referrals by date\n",
    "fight_days = fighting_referrals.groupby('Date of Incident').size().reset_index(name='fight_referrals')\n",
    "\n",
    "# Merge fighting-related referrals with weather data\n",
    "weather_fights = pd.merge(fight_days, weather_df, left_on='Date of Incident', right_on='datetime', how='inner')\n",
    "\n",
    "# Plot daily fight referrals vs. temperature\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.scatterplot(data=weather_fights, x='temp', y='fight_referrals')\n",
    "plt.title(\"Daily Fight Referrals vs. Temperature\")\n",
    "plt.xlabel(\"Temperature\")\n",
    "plt.ylabel(\"Number of Fight-Related Referrals\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Bus Conduct vs. Classroom Referrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the relationship between bus conduct incidents and classroom referrals\n",
    "bus_counts = bus_conduct_all['Student Identifier'].value_counts().reset_index()\n",
    "bus_counts.columns = ['Student Identifier', 'Bus_Incidents']\n",
    "\n",
    "referral_counts = disciplinary_referral_all['Student Identifier'].value_counts().reset_index()\n",
    "referral_counts.columns = ['Student Identifier', 'Referrals']\n",
    "\n",
    "# Merge bus conduct and referral data\n",
    "merged_behavior = pd.merge(bus_counts, referral_counts, on='Student Identifier', how='outer').fillna(0)\n",
    "\n",
    "# Plot referrals vs. bus conduct incidents\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=merged_behavior, x='Bus_Incidents', y='Referrals')\n",
    "plt.title('Referrals vs. Bus Conduct Incidents')\n",
    "plt.xlabel('Bus Conduct Incidents')\n",
    "plt.ylabel('Referrals')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Weekday Trends in Referrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze weekday trends in referrals\n",
    "disciplinary_referral_all['Weekday'] = disciplinary_referral_all['Date of Incident'].dt.day_name()\n",
    "\n",
    "# Define the order of weekdays for plotting\n",
    "weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "\n",
    "# Count referrals by weekday\n",
    "weekday_counts = disciplinary_referral_all['Weekday'].value_counts().reindex(weekday_order)\n",
    "\n",
    "# Plot referrals by day of the week\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x=weekday_counts.index, y=weekday_counts.values)\n",
    "plt.title('Referrals by Day of the Week')\n",
    "plt.ylabel('Number of Referrals')\n",
    "plt.xlabel('Day')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## 4. Hypothesis Testing\n",
    "This section explores several data-driven hypotheses relevant to predicting and minimizing in-class behavioral disruptions. The following tests were conducted using statistical methods such as t-tests, ANOVA, and correlation analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "### H1: Referral Frequency Increases Near Testing Season\n",
    "\n",
    "**Hypothesis:** March and April have significantly higher referral counts due to testing-related stress.\n",
    "\n",
    "**Test Type:** One-way ANOVA  \n",
    "**Rationale:** Compare monthly referral averages across months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaNs and extract month\n",
    "monthly_ref = disciplinary_referral_all.dropna(subset=['Date of Incident']).copy()\n",
    "monthly_ref['Month'] = monthly_ref['Date of Incident'].dt.month\n",
    "\n",
    "# Calculate number of referrals per student per month\n",
    "monthly_student_referrals = (\n",
    "    monthly_ref.groupby(['Month', 'Student Identifier'])\n",
    "    .size()\n",
    "    .reset_index(name='Referral Count')\n",
    ")\n",
    "\n",
    "# Create a list of referral counts per month for ANOVA, filter groups with more than 1 value and variance > 0\n",
    "monthly_groups = [\n",
    "    group['Referral Count'].values\n",
    "    for _, group in monthly_student_referrals.groupby('Month')\n",
    "    if len(group) > 1 and group['Referral Count'].var() > 0\n",
    "]\n",
    "\n",
    "# Perform ANOVA if valid groups exist\n",
    "if len(monthly_groups) >= 2:\n",
    "    f_stat, p_value = f_oneway(*monthly_groups)\n",
    "    print(f\"F-statistic: {f_stat:.4f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "    if not pd.isna(f_stat) and p_value < 0.05:\n",
    "        print(\"Significant differences exist between monthly referral counts.\")\n",
    "    elif not pd.isna(f_stat):\n",
    "        print(\"No significant difference between months.\")\n",
    "    else:\n",
    "        print(\"ANOVA returned NaN. Check your data again for consistency.\")\n",
    "else:\n",
    "    print(\"Not enough valid monthly groups for ANOVA.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### H2: Bus Misconduct is Associated with More In-Class Referrals\n",
    "\n",
    "**Hypothesis:** Students with bus conduct incidents have significantly more in-class referrals than those without.\n",
    "\n",
    "**Test Type:** Welch’s t-test (independent two-sample t-test)  \n",
    "**Rationale:** Compare mean referral counts between two groups (bus incident vs. no bus incident)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total referrals per student\n",
    "referral_counts = disciplinary_referral_all['Student Identifier'].value_counts().reset_index()\n",
    "referral_counts.columns = ['Student Identifier', 'Total_Referrals']\n",
    "\n",
    "# Total bus incidents per student\n",
    "bus_counts = bus_conduct_all['Student Identifier'].value_counts().reset_index()\n",
    "bus_counts.columns = ['Student Identifier', 'Bus_Incidents']\n",
    "\n",
    "# Merge datasets\n",
    "behavior_merge = pd.merge(referral_counts, bus_counts, on='Student Identifier', how='outer').fillna(0)\n",
    "\n",
    "# Create two groups\n",
    "bus_yes = behavior_merge[behavior_merge['Bus_Incidents'] > 0]['Total_Referrals']\n",
    "bus_no = behavior_merge[behavior_merge['Bus_Incidents'] == 0]['Total_Referrals']\n",
    "\n",
    "# Run t-test\n",
    "t_stat, p_value = ttest_ind(bus_yes, bus_no, equal_var=False)\n",
    "\n",
    "print(f\"T-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"Statistically significant difference found.\")\n",
    "else:\n",
    "    print(\"No significant difference.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### H3: Family Engagement Negatively Correlates with Referrals\n",
    "\n",
    "**Hypothesis:** Higher family engagement is associated with fewer referrals.\n",
    "\n",
    "**Test Type:** Spearman Correlation  \n",
    "**Rationale:** Non-parametric test of ordinal survey response counts vs. referral totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean columns and estimate total referrals per school\n",
    "referrals_by_school = disciplinary_referral_all['Please select your school'].value_counts().reset_index()\n",
    "referrals_by_school.columns = ['School', 'Total_Referrals']\n",
    "\n",
    "# Survey counts per school\n",
    "engagement_by_school = family_engagement['Please check which school your child/children attends.'].value_counts().reset_index()\n",
    "engagement_by_school.columns = ['School', 'Engagement_Survey_Responses']\n",
    "\n",
    "school_merge = pd.merge(referrals_by_school, engagement_by_school, on='School', how='inner')\n",
    "\n",
    "# Spearman correlation\n",
    "corr, p_value = spearmanr(school_merge['Engagement_Survey_Responses'], school_merge['Total_Referrals'])\n",
    "print(f\"Spearman correlation: {corr:.4f}\\nP-value: {p_value:.4f}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"Significant negative/positive correlation.\")\n",
    "else:\n",
    "    print(\"No significant correlation found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### H4: Referral Count Differs by Grade Level\n",
    "\n",
    "**Hypothesis:** Certain grades have significantly more referrals.\n",
    "\n",
    "**Test Type:** One-way ANOVA  \n",
    "**Rationale:** Compare referral frequency across grades.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure Grade_Level is numeric and drop rows with missing Grade_Level\n",
    "disciplinary_referral_all['Grade_Level'] = pd.to_numeric(disciplinary_referral_all['Grade_Level'], errors='coerce')\n",
    "ref_by_grade = disciplinary_referral_all.dropna(subset=['Grade_Level'])\n",
    "\n",
    "# Calculate number of referrals per student per grade\n",
    "grade_student_referrals = (\n",
    "    ref_by_grade.groupby(['Grade_Level', 'Student Identifier'])\n",
    "    .size()\n",
    "    .reset_index(name='Referral Count')\n",
    ")\n",
    "\n",
    "# Create a list of referral counts per grade for ANOVA, filtering for groups with variance > 0\n",
    "grade_groups = [\n",
    "    group['Referral Count'].values\n",
    "    for _, group in grade_student_referrals.groupby('Grade_Level')\n",
    "    if len(group) > 1 and group['Referral Count'].var() > 0\n",
    "]\n",
    "\n",
    "# Perform ANOVA if there are at least two valid grade groups\n",
    "if len(grade_groups) >= 2:\n",
    "    f_stat, p_value = f_oneway(*grade_groups)\n",
    "    print(f\"F-statistic: {f_stat:.4f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "    if not pd.isna(f_stat) and p_value < 0.05:\n",
    "        print(\"Referral rates differ significantly across grades.\")\n",
    "    elif not pd.isna(f_stat):\n",
    "        print(\"No significant difference in referrals between grades.\")\n",
    "    else:\n",
    "        print(\"ANOVA returned NaN. Check your data for consistency.\")\n",
    "else:\n",
    "    print(\"Not enough valid grade groups for ANOVA.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### H5: Referral Volume Correlates with Weather Factors\n",
    "\n",
    "**Hypothesis:** Temperature and humidity levels are associated with referral counts.\n",
    "\n",
    "**Test Type:** Pearson Correlation  \n",
    "**Rationale:** Compare numeric weather features against referral count per day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare merged dataset\n",
    "weather_df['datetime'] = pd.to_datetime(weather_df['datetime'], errors='coerce')\n",
    "daily_ref = disciplinary_referral_all.groupby('Date of Incident').size().reset_index(name='referral_count')\n",
    "daily_weather = pd.merge(daily_ref, weather_df, left_on='Date of Incident', right_on='datetime', how='inner')\n",
    "\n",
    "# Pearson correlations\n",
    "for var in ['temp', 'humidity']:\n",
    "    corr, p = pearsonr(daily_weather['referral_count'], daily_weather[var])\n",
    "    print(f\"Pearson correlation between referrals and {var}: {corr:.4f} (p = {p:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "## Hypothesis Testing Summary and Interpretation\n",
    "\n",
    "This section summarizes the results of five statistical tests aimed at identifying significant patterns and relationships related to student behavioral referrals. These insights support the ultimate goal of targeting interventions and informing stakeholder decision-making.\n",
    "\n",
    "---\n",
    "\n",
    "### **H1: Referral Frequency Increases Near Testing Season**\n",
    "- **F-statistic:** `NaN`  \n",
    "- **P-value:** `NaN`  \n",
    "- **Result:** *Test could not be performed due to insufficient or non-variable data.*\n",
    "\n",
    "**Interpretation:**  \n",
    "Referral data for summer months (June, July) was missing, and some months had uniform or single-entry referral counts. This lack of statistical variance violated ANOVA assumptions, making the test invalid.\n",
    "\n",
    "**Implication:**  \n",
    "A follow-up study with more balanced month-by-month data could explore whether academic testing stress correlates with behavioral disruptions.\n",
    "\n",
    "---\n",
    "\n",
    "### **H2: Bus Misconduct is Associated with More In-Class Referrals**\n",
    "- **T-statistic:** `-4.9906`  \n",
    "- **P-value:** `0.0000`  \n",
    "- **Result:** *Statistically significant difference found.*\n",
    "\n",
    "**Interpretation:**  \n",
    "Students with at least one bus conduct incident had significantly higher referral counts compared to those without. The large negative t-statistic confirms that the two group means are meaningfully different.\n",
    "\n",
    "**Implication:**  \n",
    "Bus misconduct is a strong predictor of general behavioral issues. Students flagged for bus incidents may benefit from preemptive behavioral interventions or monitoring in the classroom.\n",
    "\n",
    "---\n",
    "\n",
    "### **H3: Family Engagement Negatively Correlates with Referrals**\n",
    "- **Spearman correlation:** `-0.8000`  \n",
    "- **P-value:** `0.2000`  \n",
    "- **Result:** *Not statistically significant.*\n",
    "\n",
    "**Interpretation:**  \n",
    "While a strong negative correlation was observed (suggesting that higher engagement corresponds with fewer referrals), the p-value was not below the 0.05 threshold for significance. This may be due to small sample size (school-level aggregation).\n",
    "\n",
    "**Implication:**  \n",
    "There is potential evidence that increased family involvement could reduce behavior issues. Larger or student-level datasets may yield stronger conclusions.\n",
    "\n",
    "---\n",
    "\n",
    "### **H4: Referral Count Differs by Grade Level**\n",
    "- **F-statistic:** `NaN`  \n",
    "- **P-value:** `NaN`  \n",
    "- **Result:** *Test could not be performed due to insufficient group variability.*\n",
    "\n",
    "**Interpretation:**  \n",
    "Some grades had extremely low referral counts or lacked variation, violating ANOVA requirements. As with H1, this results in an invalid test.\n",
    "\n",
    "**Implication:**  \n",
    "FIX THIS LATER\n",
    "\n",
    "---\n",
    "\n",
    "### **H5: Weather Correlation with Referral Volume**\n",
    "- **Temperature Correlation (Pearson):** `0.1636` (p = `0.0455`)  \n",
    "- **Humidity Correlation (Pearson):** `0.1566` (p = `0.0557`) \n",
    "\n",
    "**Interpretation:**  \n",
    "There is a **weak but statistically significant** positive correlation between **temperature** and **referral volume**, indicating referrals tend to rise on warmer days. The correlation with humidity is borderline and not statistically significant at α = 0.05.\n",
    "\n",
    "**Implication:**  \n",
    "Environmental stressors such as heat may contribute to behavioral issues. Schools could explore increased support or schedule adjustments during high-heat periods.\n",
    "\n",
    "---\n",
    "\n",
    "### Overall Recommendations:\n",
    "\n",
    "- **Focus future models on bus conduct as a predictive feature.**\n",
    "- **Consider temperature as a situational risk factor.**\n",
    "- **Explore family engagement strategies to reduce referrals.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "## Initial Recommendations for School Stakeholders\n",
    "\n",
    "Based on data-driven hypothesis testing and exploratory analysis, the following recommendations are proposed to help school administrators reduce behavioral disruptions and improve classroom environments:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Monitor Students with Bus Conduct Incidents\n",
    "> **Why:** Students with bus conduct violations had *statistically significantly higher* classroom referral rates.\n",
    "\n",
    "**Recommendations:**\n",
    "- Flag students with bus write-ups for early behavioral intervention or counseling.\n",
    "- Integrate bus conduct records into early warning systems.\n",
    "- Enhance collaboration between bus drivers and classroom teachers.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Plan for Heat-Related Behavior Increases\n",
    "> **Why:** Referral counts showed a *significant positive correlation* with higher temperatures.\n",
    "\n",
    "**Recommendations:**\n",
    "- Improve classroom cooling access and hydration breaks during hot weather.\n",
    "- Train teachers in managing heat-induced student irritability.\n",
    "- Monitor referrals during heatwaves and adjust scheduling if needed.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Use Family Engagement as a Soft Predictor\n",
    "> **Why:** A strong negative (though not statistically significant) correlation was observed between family engagement and referrals.\n",
    "\n",
    "**Recommendations:**\n",
    "- Encourage increased parental participation in school events and surveys.\n",
    "- Use engagement metrics to target school-specific outreach strategies.\n",
    "- Offer incentives for family involvement in education and discipline policies.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Improve Data Collection for Temporal Analysis\n",
    "> **Why:** Missing data for summer months and inconsistent grade-level information made trend testing inconclusive.\n",
    "\n",
    "**Recommendations:**\n",
    "- Ensure consistent referral logging across all months, including summer sessions.\n",
    "- Standardize grade-level encoding across datasets.\n",
    "- Capture time-of-day and seasonal data with higher granularity.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Prioritize Multivariate Risk Profiling\n",
    "> **Why:** Bus behavior, weather, and family engagement all show predictive potential.\n",
    "\n",
    "**Recommendations:**\n",
    "- Develop internal dashboards combining behavior, attendance, engagement, and weather.\n",
    "- Group students by intervention tiers using these combined indicators.\n",
    "- Explore predictive modeling to proactively identify at-risk students.\n",
    "\n",
    "---\n",
    "\n",
    "These recommendations are intended to guide practical changes and inform predictive modeling efforts that follow in subsequent sections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering\n",
    "In this section we will create a student-week model dataset that aggregates student behavior data on a weekly basis. This will help us analyze trends and patterns in student behavior over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Merging all the datasets into one model ready dataset\n",
    "# Reload datasets\n",
    "original_ref = pd.read_csv(\"TTU Data - Disciplinary Referral.csv\")\n",
    "update_ref = pd.read_csv(\"TTU Data Update - Disciplinary Referral.csv\")\n",
    "original_bus = pd.read_csv(\"TTU Data - Bus Conduct.csv\")\n",
    "update_bus = pd.read_csv(\"TTU Data Update - Bus Conduct.csv\")\n",
    "family_engagement = pd.read_csv(\"TTU Data - Family Engagement.csv\")\n",
    "weather = pd.read_csv(\"weather.csv\")\n",
    "\n",
    "# Merge referrals\n",
    "all_ref_columns = list(set(original_ref.columns).union(set(update_ref.columns)))\n",
    "original_ref = original_ref.reindex(columns=all_ref_columns)\n",
    "update_ref = update_ref.reindex(columns=all_ref_columns)\n",
    "full_ref = pd.concat([original_ref, update_ref], ignore_index=True).drop_duplicates()\n",
    "\n",
    "# Merge bus conduct\n",
    "all_bus_columns = list(set(original_bus.columns).union(set(update_bus.columns)))\n",
    "original_bus = original_bus.reindex(columns=all_bus_columns)\n",
    "update_bus = update_bus.reindex(columns=all_bus_columns)\n",
    "full_bus = pd.concat([original_bus, update_bus], ignore_index=True).drop_duplicates()\n",
    "\n",
    "# Preprocess dates\n",
    "full_ref['Date of Incident'] = pd.to_datetime(full_ref['Date of Incident'], errors='coerce')\n",
    "full_bus['Date of Incident'] = pd.to_datetime(full_bus['Date of Incident'], errors='coerce')\n",
    "weather['datetime'] = pd.to_datetime(weather['datetime'], errors='coerce')\n",
    "\n",
    "# STEP 1: Create 'Week' columns\n",
    "full_ref['Week'] = full_ref['Date of Incident'].dt.to_period('W').apply(lambda r: r.start_time)\n",
    "full_bus['Week'] = full_bus['Date of Incident'].dt.to_period('W').apply(lambda r: r.start_time if not pd.isnull(r) else None)\n",
    "# STEP 2: Aggregate referral and bus incidents per student per week\n",
    "ref_agg = full_ref.groupby(['Student Identifier', 'Week']).size().reset_index(name='weekly_referrals')\n",
    "bus_agg = full_bus.groupby(['Student Identifier', 'Week']).size().reset_index(name='weekly_bus_incidents')\n",
    "\n",
    "# STEP 3: Extract basic student metadata\n",
    "student_meta = full_ref.drop_duplicates('Student Identifier')[['Student Identifier', 'Grade_Level', 'Gender', 'Ethnicity', 'LunchStatus']]\n",
    "\n",
    "# STEP 4: Normalize and prepare engagement survey data\n",
    "engagement_data = family_engagement.rename(columns=lambda x: x.strip())\n",
    "if 'Student Identifier' not in engagement_data.columns:\n",
    "    for col in engagement_data.columns:\n",
    "        if 'student' in col.lower() and 'id' in col.lower():\n",
    "            engagement_data.rename(columns={col: 'Student Identifier'}, inplace=True)\n",
    "            break\n",
    "\n",
    "# STEP 5: Merge referral and bus data\n",
    "student_weeks = pd.merge(ref_agg, bus_agg, on=['Student Identifier', 'Week'], how='outer').fillna(0)\n",
    "\n",
    "# STEP 6: Add student demographic data\n",
    "student_weeks = pd.merge(student_weeks, student_meta, on='Student Identifier', how='left')\n",
    "\n",
    "# STEP 7: Add engagement survey data\n",
    "student_weeks = pd.merge(student_weeks, engagement_data, on='Student Identifier', how='left')\n",
    "\n",
    "# STEP 8: Add weekly weather aggregates\n",
    "weather['Week'] = weather['datetime'].dt.to_period('W').apply(lambda r: r.start_time)\n",
    "weather_weekly = weather.groupby('Week').agg({\n",
    "    'temp': 'mean',\n",
    "    'humidity': 'mean',\n",
    "    'precip': 'mean',\n",
    "    'sealevelpressure': 'mean',\n",
    "    'windgust': 'mean'\n",
    "}).reset_index()\n",
    "student_weeks = pd.merge(student_weeks, weather_weekly, on='Week', how='left')\n",
    "\n",
    "# STEP 9: Create target variable\n",
    "student_weeks = student_weeks.sort_values(by=['Student Identifier', 'Week'])\n",
    "student_weeks['referral_next_week'] = student_weeks.groupby('Student Identifier')['weekly_referrals'].shift(-1)\n",
    "student_weeks['referral_next_week'] = (student_weeks['referral_next_week'] > 0).astype(int)\n",
    "\n",
    "# Display the result\n",
    "print(\"Model-Ready Dataset Preview:\")\n",
    "print(student_weeks.head())\n",
    "print(\"\\nShape:\", student_weeks.shape)\n",
    "print(\"Columns:\", student_weeks.columns.tolist())\n",
    "\n",
    "student_weeks.to_csv(\"model_ready_student_weeks.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "## 6. Model Development\n",
    "\n",
    "In this section, we implement logistic regression, linear regression, and an advanced Random Forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "### Loading the data and training/testing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_weeks = pd.read_csv(\"model_ready_student_weeks.csv\")\n",
    "student_weeks.dropna(subset=['referral_next_week'], inplace=True)\n",
    "\n",
    "features = ['weekly_referrals', 'weekly_bus_incidents', 'Grade_Level', 'Gender',\n",
    "            'Ethnicity', 'LunchStatus', 'temp', 'humidity', 'precip', 'sealevelpressure', 'windgust']\n",
    "\n",
    "X = student_weeks[features]\n",
    "y_classification = student_weeks['referral_next_week']\n",
    "y_regression = student_weeks['weekly_referrals']\n",
    "\n",
    "X_train, X_test, y_clf_train, y_clf_test, y_reg_train, y_reg_test = train_test_split(\n",
    "    X, y_classification, y_regression, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "### Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipelines\n",
    "numeric_features = ['weekly_referrals', 'weekly_bus_incidents', 'Grade_Level', 'temp', 'humidity', 'precip', 'sealevelpressure', 'windgust']\n",
    "categorical_features = ['Gender', 'Ethnicity', 'LunchStatus']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "### Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model pipelines\n",
    "pipelines = {\n",
    "    'LogisticRegression': ImbPipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', LogisticRegression(max_iter=1000, random_state=42))\n",
    "    ]),\n",
    "    'LinearRegression': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('clf', LinearRegression())\n",
    "    ]),\n",
    "    'NeuralNetwork': ImbPipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', MLPClassifier(hidden_layer_sizes=(50,), max_iter=300, random_state=42))\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "### Parameter Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grids\n",
    "param_grids = {\n",
    "    'LogisticRegression': {\n",
    "        'clf__C': [0.01, 0.1, 1.0, 10.0],\n",
    "        'clf__penalty': ['l2'],\n",
    "        'clf__solver': ['lbfgs']\n",
    "    },\n",
    "    'LinearRegression': {\n",
    "        'clf__fit_intercept': [True, False],\n",
    "        'clf__positive': [False, True]\n",
    "    },\n",
    "    'NeuralNetwork': {\n",
    "        'clf__hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50), (64, 64, 32)],\n",
    "        'clf__activation': ['relu', 'tanh'],\n",
    "        'clf__solver': ['adam'],\n",
    "        'clf__alpha': [0.0001, 0.001],\n",
    "        'clf__learning_rate': ['constant', 'adaptive'],\n",
    "        'clf__early_stopping': [True],\n",
    "        'clf__n_iter_no_change': [5]\n",
    "    }\n",
    "}\n",
    "\n",
    "# GridSearchCV runner\n",
    "def run_grid_searches(X_train, y_train, pipelines):\n",
    "    best_models = {}\n",
    "    for model_name, pipeline in pipelines.items():\n",
    "        if model_name not in param_grids:\n",
    "            print(f\"Skipping model: {model_name}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nTuning hyperparameters for: {model_name}...\")\n",
    "\n",
    "        grid = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=param_grids[model_name],\n",
    "            cv=5,\n",
    "            scoring='f1_macro' if model_name != 'LinearRegression' else 'r2',\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        grid.fit(X_train, y_train)\n",
    "        best_models[model_name] = grid\n",
    "\n",
    "        print(f\"\\nBest Params for {model_name}: {grid.best_params_}\")\n",
    "        print(f\"Best Score: {grid.best_score_:.4f}\")\n",
    "\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "### DBSCAN Clustering Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dbscan(X_raw):\n",
    "    # Preprocess the data\n",
    "    X_numeric = X_raw.select_dtypes(include=[np.number])\n",
    "    X_numeric = pd.DataFrame(SimpleImputer(strategy=\"mean\").fit_transform(X_numeric), columns=X_numeric.columns)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_numeric)\n",
    "\n",
    "    # Parameter ranges\n",
    "    eps_vals = np.arange(0.1, 1.1, 0.1)\n",
    "    min_samples_vals = [3, 5, 7]\n",
    "\n",
    "    best_score = -1\n",
    "    best_model = None\n",
    "    best_params = None\n",
    "\n",
    "    # Iterate over parameter combinations\n",
    "    for eps in eps_vals:\n",
    "        for min_samples in min_samples_vals:\n",
    "            model = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "            labels = model.fit_predict(X_scaled)\n",
    "            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "            if n_clusters < 2:\n",
    "                print(f\"Skipped eps={eps:.1f}, min_samples={min_samples} — only {n_clusters} cluster(s) detected\")\n",
    "                continue\n",
    "\n",
    "            score = silhouette_score(X_scaled, labels)\n",
    "            print(f\"Checked eps={eps:.1f}, min_samples={min_samples} → Silhouette Score: {score:.4f}\")\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_model = model\n",
    "                best_params = {'eps': eps, 'min_samples': min_samples}\n",
    "\n",
    "    if best_model:\n",
    "        print(\"\\nBest DBSCAN Params:\", best_params)\n",
    "        print(\"Best Silhouette Score:\", best_score)\n",
    "    else:\n",
    "        print(\"No valid DBSCAN clustering found. Adjust parameter ranges or examine dataset scale.\")\n",
    "\n",
    "    return best_model, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "## 7. Model Evaluation and Interpretation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_results(best_models, X_test, y_clf_test, y_reg_test):\n",
    "    for name, model in best_models.items():\n",
    "        print(f\"\\nEvaluation Results for {name}\")\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Always compute RMSE and R² for consistency\n",
    "        try:\n",
    "            rmse = root_mean_squared_error(y_reg_test, y_pred)\n",
    "            r2 = r2_score(y_reg_test, y_pred)\n",
    "            print(f\"RMSE: {rmse:.4f}\")\n",
    "            print(f\"R² Score: {r2:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(\"[RMSE/R² Calculation Error]:\", e)\n",
    "\n",
    "        if name != 'LinearRegression':\n",
    "            try:\n",
    "                cm = confusion_matrix(y_clf_test, y_pred)\n",
    "                prec = precision_score(y_clf_test, y_pred)\n",
    "                rec = recall_score(y_clf_test, y_pred)\n",
    "                f1 = f1_score(y_clf_test, y_pred)\n",
    "\n",
    "                print(f\"Precision: {prec:.4f}\")\n",
    "                print(f\"Recall: {rec:.4f}\")\n",
    "                print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "                plt.figure(figsize=(5, 4))\n",
    "                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "                plt.title(f\"{name} — Confusion Matrix\")\n",
    "                plt.xlabel(\"Predicted\")\n",
    "                plt.ylabel(\"Actual\")\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            except Exception as e:\n",
    "                print(\"[Classification Metrics Error]:\", e)\n",
    "        else:\n",
    "            # Regression scatter plot only for linear regression\n",
    "            plt.figure(figsize=(6, 4))\n",
    "            plt.scatter(y_reg_test, y_pred, alpha=0.3)\n",
    "            plt.title(f'{name} — Actual vs. Predicted Referrals')\n",
    "            plt.xlabel(\"Actual Referrals\")\n",
    "            plt.ylabel(\"Predicted Referrals\")\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "# Usage:\n",
    "best_models = run_grid_searches(X_train, y_clf_train, pipelines)\n",
    "evaluate_model_results(best_models, X_test, y_clf_test, y_reg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "### DBSCAN Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dbscan_clusters(dbscan_model, X_raw, preprocessor):\n",
    "    if dbscan_model is None:\n",
    "        print(\"DBSCAN model is None — check if a valid model was returned from evaluate_dbscan().\")\n",
    "        return\n",
    "\n",
    "    X_preprocessed = preprocessor.fit_transform(X_raw)\n",
    "    labels = dbscan_model.fit_predict(X_preprocessed)\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced = pca.fit_transform(X_preprocessed)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scatter = plt.scatter(reduced[:, 0], reduced[:, 1], c=labels, cmap='tab10', s=20, alpha=0.6)\n",
    "    plt.title(\"DBSCAN Cluster Visualization (PCA-Reduced)\")\n",
    "    plt.xlabel(\"PCA Component 1\")\n",
    "    plt.ylabel(\"PCA Component 2\")\n",
    "    plt.grid(True)\n",
    "    plt.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "best_dbscan, best_score = evaluate_dbscan(X)\n",
    "if best_dbscan:\n",
    "    visualize_dbscan_clusters(best_dbscan, X, preprocessor)\n",
    "else:\n",
    "    print(\"No valid DBSCAN model was found. Please adjust the parameters or check the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "## Model Interpretation\n",
    "\"\"\"\n",
    "\n",
    "### Overview\n",
    "This section interprets the output of the evaluated models — Logistic Regression, Linear Regression, Neural Network, and DBSCAN — providing context for what the results mean and implications for the school district.\n",
    "\n",
    "---\n",
    "\n",
    "### Logistic Regression\n",
    "- **Precision**: 0.6625\n",
    "- **Recall**: 0.6883\n",
    "- **F1 Score**: 0.6752\n",
    "\n",
    "**Interpretation**: Logistic regression performed reasonably well in predicting students who would have a referral the following week. A recall of ~69% means it correctly identified most of the actual positive cases (disruptive students), while a precision of ~66% shows a moderate rate of false positives. Its F1 score (0.6752) balances both measures effectively, making it a good baseline classifier.\n",
    "\n",
    "---\n",
    "\n",
    "### Linear Regression\n",
    "- **RMSE**: 0.7571\n",
    "- **R²**: -0.2022\n",
    "\n",
    "**Interpretation**: The model's R² is negative, indicating that it performs worse than simply predicting the mean value for all observations. The linear regression model failed to capture patterns in the data to predict the number of weekly referrals accurately, suggesting the relationship is not linear or lacks strong predictive variables.\n",
    "\n",
    "---\n",
    "\n",
    "### Neural Network\n",
    "- **Precision**: 0.5500\n",
    "- **Recall**: 0.4286\n",
    "- **F1 Score**: 0.4818\n",
    "\n",
    "**Interpretation**: The neural network underperformed compared to logistic regression. Its lower recall (42.86%) indicates a tendency to miss actual referral cases, and its overall F1 score (0.4818) suggests it's less reliable in high-stakes prediction. This may indicate overfitting or sensitivity to data imbalance.\n",
    "\n",
    "---\n",
    "\n",
    "### DBSCAN Clustering\n",
    "- **Best Params**: eps=0.8, min_samples=3\n",
    "- **Best Silhouette Score**: 0.4634\n",
    "\n",
    "**Interpretation**: DBSCAN discovered moderately well-separated clusters (silhouette ~0.46). These clusters could correspond to different behavior profiles or referral risk tiers. However, the silhouette score indicates that many points lie near cluster boundaries, suggesting some overlap or noise in student behavior patterns.\n",
    "\n",
    "---\n",
    "\n",
    "### General Takeaways\n",
    "- **Logistic Regression** is the most effective supervised method for this classification task, offering the best balance between false positives and missed referrals.\n",
    "- **Linear Regression** is ineffective for predicting the number of referrals.\n",
    "- **Neural Networks** may benefit from more data, better class balancing, or hyperparameter tuning.\n",
    "- **DBSCAN** shows potential for uncovering behavioral profiles but may require further feature selection or tuning.\n",
    "\n",
    "**Recommendations**:\n",
    "- Continue with Logistic Regression for prediction.\n",
    "- Explore ensemble methods (e.g., Random Forest, Gradient Boosting).\n",
    "- Investigate feature interactions and apply dimensionality reduction techniques.\n",
    "- Use DBSCAN output to flag outliers for intervention or manual review.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "## 8. Result Cleanup\n",
    "*(To be completed by team)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
