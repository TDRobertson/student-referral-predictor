{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "0"
   },
   "source": [
    "# Data Mining Project: Predicting Student Behavioral Disruptions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "1"
   },
   "source": [
    "## Library Requirements\n",
    "Install the required libraries specified in the `requirements.txt` file. You can do this using pip:\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "id": "2"
   },
   "source": [
    "\n",
    "## Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Data Loading and Initial Exploration](#data-loading)\n",
    "3. [Exploratory Data Analysis (EDA)](#eda)\n",
    "4. [Hypothesis Testing](#hypothesis-testing)\n",
    "5. [Feature Engineering](#feature-engineering)\n",
    "6. [Model Development](#model-development)\n",
    "7. [Model Evaluation and Interpretation](#model-evaluation)\n",
    "8. [Summary](#Summary)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "id": "3"
   },
   "source": [
    "## 1. Introduction\n",
    "This notebook documents our team's effort to predict and analyze student behavioral disruptions to minimize in-class interruptions.\n",
    "\n",
    "**Team Members:**  Thomas Robertson, Claudia Nething, Revel Etheridge, Logan Bolton\n",
    "\n",
    "**Customer:** Adam West\n",
    "\n",
    "**Objectives:**\n",
    "- Predict behavioral disruptions\n",
    "- Identify anomalous patterns\n",
    "- Provide clear interpretations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "4"
   },
   "source": [
    "## 2. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5",
    "outputId": "4b05e260-bb9f-458e-90a5-e9bb67c5dd1c"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import f_oneway, ttest_ind, spearmanr, pearsonr\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    accuracy_score, mean_squared_error, r2_score\n",
    ")\n",
    "from sklearn.base import is_classifier, is_regressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import root_mean_squared_error  # Import the new function\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, r2_score, mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.linear_model      import (\n",
    "    PoissonRegressor,\n",
    "    Ridge, Lasso, ElasticNet,\n",
    "    HuberRegressor,\n",
    "    RANSACRegressor\n",
    ")\n",
    "from sklearn.ensemble           import (\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor\n",
    ")\n",
    "from sklearn.pipeline          import Pipeline\n",
    "from sklearn.compose           import ColumnTransformer\n",
    "from sklearn.preprocessing     import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute            import SimpleImputer\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.discrete.discrete_model import NegativeBinomial\n",
    "\n",
    "from sklearn.linear_model import (\n",
    "    PoissonRegressor, Ridge, Lasso, ElasticNet,\n",
    "    HuberRegressor, RANSACRegressor\n",
    ")\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import scipy.stats as stats\n",
    "import scikit_posthocs as sp\n",
    "from sklearn.inspection import permutation_importance\n",
    "# Load datasets\n",
    "bus_conduct = pd.read_csv('TTU Data - Bus Conduct.csv')\n",
    "bus_conduct_updated = pd.read_csv('TTU Data Update - Bus Conduct.csv')\n",
    "family_engagement = pd.read_csv('TTU Data - Family Engagement.csv')\n",
    "disciplinary_referral = pd.read_csv('TTU Data - Disciplinary Referral.csv')\n",
    "disciplinary_referral_updated = pd.read_csv('TTU Data Update - Disciplinary Referral.csv')\n",
    "weather_df = pd.read_csv('weather.csv')\n",
    "\n",
    "# Display the first few rows of each dataset for inspection\n",
    "print(\"Bus Conduct Dataset:\")\n",
    "display(bus_conduct.head())\n",
    "print(\"Bus Conduct Updated Dataset:\")\n",
    "display(bus_conduct_updated.head())\n",
    "\n",
    "print(\"Family Engagement Dataset:\")\n",
    "display(family_engagement.head())\n",
    "\n",
    "print(\"Disciplinary Referral Dataset:\")\n",
    "display(disciplinary_referral.head())\n",
    "\n",
    "print(\"Disciplinary Referral Updated Dataset:\")\n",
    "display(disciplinary_referral_updated.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "id": "6"
   },
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7",
    "outputId": "c3d4ef4e-66e1-40cf-ac21-7f401cc562f8"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Combine and clean datasets\n",
    "disciplinary_referral_all = pd.concat([disciplinary_referral, disciplinary_referral_updated], ignore_index=True).drop_duplicates()\n",
    "bus_conduct_all = pd.concat([bus_conduct, bus_conduct_updated], ignore_index=True).drop_duplicates()\n",
    "# Convert date columns to datetime format\n",
    "disciplinary_referral_all['Date of Incident'] = pd.to_datetime(disciplinary_referral_all['Date of Incident'], errors='coerce')\n",
    "bus_conduct_all['Date of Incident'] = pd.to_datetime(bus_conduct_all['Date of Incident'], errors='coerce')\n",
    "# Save combined datasets to CSV files\n",
    "disciplinary_referral_all.to_csv(\"combined_disciplinary_referrals.csv\", index=False)\n",
    "bus_conduct_all.to_csv(\"combined_bus_conduct.csv\", index=False)\n",
    "# Check for missing values in the combined datasets\n",
    "print(\"Missing values in Combined Bus Conduct Data:\")\n",
    "print(bus_conduct_all.isnull().sum())\n",
    "print(\"\\nMissing values in Combined Disciplinary Referral Data:\")\n",
    "print(disciplinary_referral_all.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "8",
    "outputId": "f2a6bb4a-ce9f-45ee-df9e-43191f3e0687"
   },
   "outputs": [],
   "source": [
    "# Add a 'Month' column for monthly analysis\n",
    "disciplinary_referral_all['Month'] = disciplinary_referral_all['Date of Incident'].dt.month\n",
    "\n",
    "# Group by month and count referrals\n",
    "monthly_referrals = disciplinary_referral_all.groupby('Month').size()\n",
    "\n",
    "# Plot monthly referral counts\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=monthly_referrals.index, y=monthly_referrals.values)\n",
    "plt.title('Monthly Disciplinary Referrals (Updated Dataset)')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Referrals')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "9",
    "outputId": "d948dd9b-2fcb-45f7-94ab-e2786deb7a04"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Identify the top 10 students with the most referrals\n",
    "frequent_students = disciplinary_referral_all['Student Identifier'].value_counts().head(10)\n",
    "\n",
    "# Plot the top 10 students by referral count\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(y=frequent_students.index, x=frequent_students.values, orient='h')\n",
    "plt.title('Top 10 Students by Number of Referrals (Updated Dataset)')\n",
    "plt.xlabel('Number of Referrals')\n",
    "plt.ylabel('Student Identifier')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643
    },
    "id": "10",
    "outputId": "2eb48afc-3908-4e2f-fc55-97f5aad527cf"
   },
   "outputs": [],
   "source": [
    "# Function to categorize time of day\n",
    "def categorize_time(time_str):\n",
    "    if pd.isna(time_str): return \"Unknown\"\n",
    "    time_str = time_str.lower().strip()\n",
    "    if \"before school\" in time_str: return \"Before School\"\n",
    "    elif any(t in time_str for t in [\"8:00am\", \"9:00am\", \"10:00am\", \"11:00am\"]): return \"Morning\"\n",
    "    elif any(t in time_str for t in [\"12:00pm\", \"1:00pm\"]): return \"Early Afternoon\"\n",
    "    elif any(t in time_str for t in [\"2:00pm\", \"3:00pm\"]): return \"Late Afternoon\"\n",
    "    elif \"after school\" in time_str: return \"After School\"\n",
    "    else: return \"Other\"\n",
    "\n",
    "# Define the order of time categories\n",
    "time_order = [\"Before School\", \"Morning\", \"Early Afternoon\", \"Late Afternoon\", \"After School\", \"Other\"]\n",
    "\n",
    "# Apply time categorization to the dataset\n",
    "disciplinary_referral_all[\"Time_Category\"] = disciplinary_referral_all[\"Time of the Day the behavior occurred?\"].apply(categorize_time)\n",
    "\n",
    "# Set ordered categories for plotting\n",
    "disciplinary_referral_all[\"Time_Category\"] = pd.Categorical(\n",
    "    disciplinary_referral_all[\"Time_Category\"],\n",
    "    categories=time_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Group data by grade level and time category\n",
    "grouped = disciplinary_referral_all.groupby([\"Grade_Level\", \"Time_Category\"]).size().unstack().fillna(0)\n",
    "\n",
    "# Sort grades for display\n",
    "grouped = grouped.sort_index()\n",
    "\n",
    "# Plot a heatmap of referrals by grade level and time of day\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(grouped, annot=True, fmt='d', cmap=\"YlGnBu\")\n",
    "plt.title(\"Disciplinary Referrals by Grade Level and Time of Day (Cleaned)\")\n",
    "plt.xlabel(\"Time of Day\")\n",
    "plt.ylabel(\"Grade Level\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "id": "11",
    "outputId": "59749e99-2e12-4cfb-a4c9-b6e3149ddd62"
   },
   "outputs": [],
   "source": [
    "# Convert weather data datetime column to datetime format\n",
    "weather_df['datetime'] = pd.to_datetime(weather_df['datetime'], errors='coerce')\n",
    "\n",
    "# Group referrals by date and count\n",
    "referrals_per_day = disciplinary_referral_all.groupby('Date of Incident').size().reset_index(name='referral_count')\n",
    "\n",
    "# Merge referral counts with weather data\n",
    "merged_df = pd.merge(referrals_per_day, weather_df, how='inner', left_on='Date of Incident', right_on='datetime')\n",
    "merged_df.drop(columns=['datetime'], inplace=True)\n",
    "\n",
    "# Categorize temperature into bins\n",
    "bins = [0, 50, 70, 100]\n",
    "labels = ['Cold (<50°F)', 'Mild (50-70°F)', 'Hot (>70°F)']\n",
    "merged_df['Temp_Category'] = pd.cut(merged_df['temp'], bins=bins, labels=labels)\n",
    "\n",
    "# Calculate average referrals by temperature category\n",
    "binned_referrals = merged_df.groupby('Temp_Category')['referral_count'].mean().reset_index()\n",
    "\n",
    "# Plot average referrals by temperature category\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=binned_referrals, x='Temp_Category', y='referral_count', palette='coolwarm')\n",
    "plt.title('Average Referrals by Temperature (Updated)')\n",
    "plt.ylabel('Average Number of Referrals')\n",
    "plt.xlabel('Temperature Range')\n",
    "plt.grid(True, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "id": "12"
   },
   "source": [
    "## 3.5 Expanded EDA: Additional Insights and Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "id": "13"
   },
   "source": [
    "## Expanded EDA: Additional Insights and Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "id": "14"
   },
   "source": [
    "### Referrals by School"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "15",
    "outputId": "c25193a4-4c2c-4923-f25a-71c85c43709d"
   },
   "outputs": [],
   "source": [
    "# Analyze referrals by school or staff\n",
    "staff_referral_counts = disciplinary_referral_all['Please select your school'].value_counts().head(10)\n",
    "\n",
    "# Plot the top 10 schools by referral count\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(y=staff_referral_counts.index, x=staff_referral_counts.values, orient='h')\n",
    "plt.title(\"Top 10 Schools by Referral Count\")\n",
    "plt.xlabel(\"Referrals Issued\")\n",
    "plt.ylabel(\"School\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "id": "16"
   },
   "source": [
    "Weather and Referral Type (e.g Fighting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "id": "17",
    "outputId": "c0107149-828f-49c5-d839-096f35278f8e"
   },
   "outputs": [],
   "source": [
    "# Analyze weather and referral type (e.g., fighting-related referrals)\n",
    "fighting_referrals = disciplinary_referral_all[\n",
    "    disciplinary_referral_all['Select the Major Referral'].str.contains('fight', na=False, case=False)\n",
    "]\n",
    "\n",
    "# Group fighting-related referrals by date\n",
    "fight_days = fighting_referrals.groupby('Date of Incident').size().reset_index(name='fight_referrals')\n",
    "\n",
    "# Merge fighting-related referrals with weather data\n",
    "weather_fights = pd.merge(fight_days, weather_df, left_on='Date of Incident', right_on='datetime', how='inner')\n",
    "\n",
    "# Plot daily fight referrals vs. temperature\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.scatterplot(data=weather_fights, x='temp', y='fight_referrals')\n",
    "plt.title(\"Daily Fight Referrals vs. Temperature\")\n",
    "plt.xlabel(\"Temperature\")\n",
    "plt.ylabel(\"Number of Fight-Related Referrals\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "id": "18"
   },
   "source": [
    "### Bus Conduct vs. Classroom Referrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "19",
    "outputId": "e9eff580-2423-4e4b-abb7-0630ed388eb2"
   },
   "outputs": [],
   "source": [
    "# Analyze the relationship between bus conduct incidents and classroom referrals\n",
    "bus_counts = bus_conduct_all['Student Identifier'].value_counts().reset_index()\n",
    "bus_counts.columns = ['Student Identifier', 'Bus_Incidents']\n",
    "\n",
    "referral_counts = disciplinary_referral_all['Student Identifier'].value_counts().reset_index()\n",
    "referral_counts.columns = ['Student Identifier', 'Referrals']\n",
    "\n",
    "# Merge bus conduct and referral data\n",
    "merged_behavior = pd.merge(bus_counts, referral_counts, on='Student Identifier', how='outer').fillna(0)\n",
    "\n",
    "# Plot referrals vs. bus conduct incidents\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=merged_behavior, x='Bus_Incidents', y='Referrals')\n",
    "plt.title('Referrals vs. Bus Conduct Incidents')\n",
    "plt.xlabel('Bus Conduct Incidents')\n",
    "plt.ylabel('Referrals')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "id": "20"
   },
   "source": [
    "### Weekday Trends in Referrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "21",
    "outputId": "f23a215f-b200-4b21-e9cc-1350a289fe01"
   },
   "outputs": [],
   "source": [
    "# Analyze weekday trends in referrals\n",
    "disciplinary_referral_all['Weekday'] = disciplinary_referral_all['Date of Incident'].dt.day_name()\n",
    "\n",
    "# Define the order of weekdays for plotting\n",
    "weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']\n",
    "\n",
    "# Count referrals by weekday\n",
    "weekday_counts = disciplinary_referral_all['Weekday'].value_counts().reindex(weekday_order)\n",
    "\n",
    "# Plot referrals by day of the week\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x=weekday_counts.index, y=weekday_counts.values)\n",
    "plt.title('Referrals by Day of the Week')\n",
    "plt.ylabel('Number of Referrals')\n",
    "plt.xlabel('Day')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "id": "22"
   },
   "source": [
    "## 4. Hypothesis Testing\n",
    "This section explores several data-driven hypotheses relevant to predicting and minimizing in-class behavioral disruptions. The following tests were conducted using statistical methods such as t-tests, ANOVA, and correlation analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {
    "id": "23"
   },
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "id": "24"
   },
   "source": [
    "### H1: Referral Frequency Increases Near Testing Season\n",
    "\n",
    "**Hypothesis:** Certain Months have significantly higher referral counts due to testing-related stress.\n",
    "\n",
    "**Test Type:** One-way ANOVA  \n",
    "\n",
    "**Rationale:** Compare monthly referral averages across months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "25",
    "outputId": "03c701e7-31bb-4cb5-d09f-a9e6937f729b"
   },
   "outputs": [],
   "source": [
    "# Drop NaNs and extract month\n",
    "monthly_ref = disciplinary_referral_all.dropna(subset=['Date of Incident']).copy()\n",
    "monthly_ref['Month'] = monthly_ref['Date of Incident'].dt.month\n",
    "\n",
    "# Calculate number of referrals per student per month\n",
    "monthly_student_referrals = (\n",
    "    monthly_ref.groupby(['Month', 'Student Identifier'])\n",
    "    .size()\n",
    "    .reset_index(name='Referral Count')\n",
    ")\n",
    "\n",
    "# Create a list of referral counts per month for ANOVA, filter groups with more than 1 value and variance > 0\n",
    "monthly_groups = [\n",
    "    group['Referral Count'].values\n",
    "    for _, group in monthly_student_referrals.groupby('Month')\n",
    "    if len(group) > 1 and group['Referral Count'].var() > 0\n",
    "]\n",
    "\n",
    "# Perform ANOVA if valid groups exist\n",
    "if len(monthly_groups) >= 2:\n",
    "    f_stat, p_value = f_oneway(*monthly_groups)\n",
    "    print(f\"F-statistic: {f_stat:.4f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "    if not pd.isna(f_stat) and p_value < 0.05:\n",
    "        print(\"Significant differences exist between monthly referral counts.\")\n",
    "    elif not pd.isna(f_stat):\n",
    "        print(\"No significant difference between months.\")\n",
    "    else:\n",
    "        print(\"ANOVA returned NaN. Check your data again for consistency.\")\n",
    "else:\n",
    "    print(\"Not enough valid monthly groups for ANOVA.\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "id": "26"
   },
   "source": [
    "---\n",
    "\n",
    "### H2: Bus Misconduct is Associated with More In-Class Referrals\n",
    "\n",
    "**Hypothesis:** Students with bus conduct incidents have significantly more in-class referrals than those without.\n",
    "\n",
    "**Test Type:** Welch’s t-test (independent two-sample t-test)  \n",
    "\n",
    "**Rationale:** Compare mean referral counts between two groups (bus incident vs. no bus incident)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "27",
    "outputId": "db07aaff-c1f0-4a1b-fba5-6ef065444168"
   },
   "outputs": [],
   "source": [
    "# Total referrals per student\n",
    "referral_counts = disciplinary_referral_all['Student Identifier'].value_counts().reset_index()\n",
    "referral_counts.columns = ['Student Identifier', 'Total_Referrals']\n",
    "\n",
    "# Total bus incidents per student\n",
    "bus_counts = bus_conduct_all['Student Identifier'].value_counts().reset_index()\n",
    "bus_counts.columns = ['Student Identifier', 'Bus_Incidents']\n",
    "\n",
    "# Merge datasets\n",
    "behavior_merge = pd.merge(referral_counts, bus_counts, on='Student Identifier', how='outer').fillna(0)\n",
    "\n",
    "# Create two groups\n",
    "bus_yes = behavior_merge[behavior_merge['Bus_Incidents'] > 0]['Total_Referrals']\n",
    "bus_no = behavior_merge[behavior_merge['Bus_Incidents'] == 0]['Total_Referrals']\n",
    "\n",
    "# Run t-test\n",
    "t_stat, p_value = ttest_ind(bus_yes, bus_no, equal_var=False)\n",
    "\n",
    "print(f\"T-statistic: {t_stat:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"Statistically significant difference found.\")\n",
    "else:\n",
    "    print(\"No significant difference.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28",
   "metadata": {
    "id": "28"
   },
   "source": [
    "---\n",
    "\n",
    "### H3: Family Engagement Negatively Correlates with Referrals\n",
    "\n",
    "**Hypothesis:** Higher family engagement is associated with fewer referrals.\n",
    "\n",
    "**Test Type:** Spearman Correlation \n",
    " \n",
    "**Rationale:** Non-parametric test of ordinal survey response counts vs. referral totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29",
    "outputId": "15ff9122-4655-482c-f9a5-657ec091e65f"
   },
   "outputs": [],
   "source": [
    "# Clean columns and estimate total referrals per school\n",
    "referrals_by_school = disciplinary_referral_all['Please select your school'].value_counts().reset_index()\n",
    "referrals_by_school.columns = ['School', 'Total_Referrals']\n",
    "\n",
    "# Survey counts per school\n",
    "engagement_by_school = family_engagement['Please check which school your child/children attends.'].value_counts().reset_index()\n",
    "engagement_by_school.columns = ['School', 'Engagement_Survey_Responses']\n",
    "\n",
    "school_merge = pd.merge(referrals_by_school, engagement_by_school, on='School', how='inner')\n",
    "\n",
    "# Spearman correlation\n",
    "corr, p_value = spearmanr(school_merge['Engagement_Survey_Responses'], school_merge['Total_Referrals'])\n",
    "print(f\"Spearman correlation: {corr:.4f}\\nP-value: {p_value:.4f}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"Significant negative/positive correlation.\")\n",
    "else:\n",
    "    print(\"No significant correlation found.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30",
   "metadata": {
    "id": "30"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "### H4: Total Referral Count Differs by Grade Level\n",
    "\n",
    "**Hypothesis:** Certain grades have significantly more referrals.\n",
    "\n",
    "**Test Type:** One-way ANOVA  \n",
    "\n",
    "**Rationale:** Compare referral frequency across grades.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "31",
    "outputId": "6c0a9186-7c89-43d0-9485-ea6ad0cee87b"
   },
   "outputs": [],
   "source": [
    "# Ensure Grade_Level is numeric and drop rows with missing Grade_Level\n",
    "disciplinary_referral_all['Grade_Level'] = pd.to_numeric(disciplinary_referral_all['Grade_Level'], errors='coerce')\n",
    "ref_by_grade = disciplinary_referral_all.dropna(subset=['Grade_Level'])\n",
    "\n",
    "# Calculate number of referrals per student per grade\n",
    "grade_student_referrals = (\n",
    "    ref_by_grade.groupby(['Grade_Level', 'Student Identifier'])\n",
    "    .size()\n",
    "    .reset_index(name='Referral Count')\n",
    ")\n",
    "\n",
    "# Create a list of referral counts per grade for ANOVA, filtering for groups with variance > 0\n",
    "grade_groups = [\n",
    "    group['Referral Count'].values\n",
    "    for _, group in grade_student_referrals.groupby('Grade_Level')\n",
    "    if len(group) > 1 and group['Referral Count'].var() > 0\n",
    "]\n",
    "\n",
    "# Perform ANOVA if there are at least two valid grade groups\n",
    "if len(grade_groups) >= 2:\n",
    "    f_stat, p_value = f_oneway(*grade_groups)\n",
    "    print(f\"F-statistic: {f_stat:.4f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "    if not pd.isna(f_stat) and p_value < 0.05:\n",
    "        print(\"Referral rates differ significantly across grades.\")\n",
    "    elif not pd.isna(f_stat):\n",
    "        print(\"No significant difference in referrals between grades.\")\n",
    "    else:\n",
    "        print(\"ANOVA returned NaN. Check your data for consistency.\")\n",
    "else:\n",
    "    print(\"Not enough valid grade groups for ANOVA.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32",
   "metadata": {
    "id": "32"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "### H5: Referral Volume Correlates with Weather Factors\n",
    "\n",
    "**Hypothesis:** Temperature and humidity levels are associated with referral counts.\n",
    "\n",
    "**Test Type:** Pearson Correlation  \n",
    "\n",
    "**Rationale:** Compare numeric weather features against referral count per day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "33",
    "outputId": "fc46cc25-c7ea-4bdb-fd90-736df3da046a"
   },
   "outputs": [],
   "source": [
    "# Prepare merged dataset\n",
    "weather_df['datetime'] = pd.to_datetime(weather_df['datetime'], errors='coerce')\n",
    "daily_ref = disciplinary_referral_all.groupby('Date of Incident').size().reset_index(name='referral_count')\n",
    "daily_weather = pd.merge(daily_ref, weather_df, left_on='Date of Incident', right_on='datetime', how='inner')\n",
    "\n",
    "# Pearson correlations\n",
    "for var in ['temp', 'humidity']:\n",
    "    corr, p = pearsonr(daily_weather['referral_count'], daily_weather[var])\n",
    "    print(f\"Pearson correlation between referrals and {var}: {corr:.4f} (p = {p:.4f})\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34",
   "metadata": {
    "id": "W5DYgUltJ-6D"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "### H6: Referral Volume Correlates with Weather Factors part 2\n",
    "\n",
    "**Hypothesis:** Referrals are correlated with temperature and immediatley after and before school breaks as students get antsy to have off.\n",
    "\n",
    "**Test Type:** Dunn's Post-Hoc Test\n",
    "\n",
    "**Rationale:** Compare termperature ranges and school breaks with the number of referrals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "id": "In2uxslKKP-T",
    "outputId": "0057f6e8-7a22-411b-c745-4549a01a86bb"
   },
   "outputs": [],
   "source": [
    "merged_df['Date of Incident'] = pd.to_datetime(merged_df['Date of Incident'])\n",
    "\n",
    "# aggregate referral count and temperature per day\n",
    "daily_data = merged_df.groupby('Date of Incident').agg({\n",
    "    'referral_count': 'sum',  \n",
    "    'temp': 'mean'           \n",
    "}).reset_index()\n",
    "\n",
    "# define school breaks with colors\n",
    "breaks = {\n",
    "    'Thanksgiving Break': ('2024-11-26', '2024-11-29', 'orange'),\n",
    "    'Fall Break': ('2024-10-12', '2024-10-17', 'red'),\n",
    "    'Winter Break': ('2024-12-22', '2025-01-07', 'blue'),\n",
    "    'Spring Break': ('2024-03-30', '2024-04-04', 'green'),\n",
    "    'Summer Break': ('2024-05-18', '2024-08-8', 'purple'),\n",
    "}\n",
    "\n",
    "# categorize each day\n",
    "def label_day(date):\n",
    "    for break_name, (start_str, end_str, _) in breaks.items():\n",
    "        start = pd.to_datetime(start_str)\n",
    "        end = pd.to_datetime(end_str)\n",
    "        if start - pd.Timedelta(days=5) <= date < start:\n",
    "            return \"Before Break\"\n",
    "        elif start <= date <= end:\n",
    "            return \"During Break\"\n",
    "        elif end < date <= end + pd.Timedelta(days=5):\n",
    "            return \"After Break\"\n",
    "    return \"Regular Day\"\n",
    "\n",
    "# Apply labels\n",
    "daily_data['Break Period'] = daily_data['Date of Incident'].apply(label_day)\n",
    "\n",
    "# Perform Dunn's post-hoc test with Bonferroni correction\n",
    "dunn_results = sp.posthoc_dunn(\n",
    "    daily_data, \n",
    "    val_col='referral_count', \n",
    "    group_col='Break Period', \n",
    "    p_adjust='bonferroni'\n",
    ")\n",
    "\n",
    "# Show results\n",
    "print(\"\\nDunn's Post-Hoc Test Results (p-values):\")\n",
    "print(dunn_results)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# plot referrals\n",
    "ax1.plot(daily_data['Date of Incident'], daily_data['referral_count'], label='Referrals', color='black')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Referral Count', color='black')\n",
    "ax1.tick_params(axis='y', labelcolor='black')\n",
    "\n",
    "# highlight break periods\n",
    "for name, (start, end, color) in breaks.items():\n",
    "    ax1.axvspan(pd.to_datetime(start), pd.to_datetime(end), color=color, alpha=0.3, label=name)\n",
    "\n",
    "# temperature on secondary y-axis\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(daily_data['Date of Incident'], daily_data['temp'], label='Temperature', color='red')\n",
    "ax2.set_ylabel('Temperature (°F)', color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# combine legends\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "\n",
    "plt.title('Daily Referrals and Temperature with School Breaks Highlighted')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36",
   "metadata": {
    "id": "34"
   },
   "source": [
    "## Hypothesis Testing Summary and Interpretation\n",
    "\n",
    "This section summarizes the results of six statistical tests aimed at identifying significant patterns and relationships related to student behavioral referrals. These insights support the ultimate goal of targeting interventions and informing stakeholder decision-making.\n",
    "\n",
    "---\n",
    "\n",
    "### **H1: Referral Frequency Increases Near Testing Season**\n",
    "- **F-statistic:** `3.4566`  \n",
    "- **P-value:** `0.0004`  \n",
    "- **Result:** *Statistically significant: referral frequency increases near testing season*\n",
    "\n",
    "**Interpretation:**  \n",
    "There is a strong correlation between the month and increased referral counts. From the visual inspection of earlier graphs, this is likely due to academic stress from testing periods. The F-statistic indicates a meaningful difference in means across months.\n",
    "\n",
    "**Implication:**  \n",
    "A follow-up study with more balanced month-by-month data could explore whether academic testing stress correlates with behavioral disruptions.\n",
    "\n",
    "---\n",
    "\n",
    "### **H2: Bus Misconduct is Associated with More In-Class Referrals**\n",
    "- **T-statistic:** `-4.9906`  \n",
    "- **P-value:** `0.0000`  \n",
    "- **Result:** *Statistically significant difference found.*\n",
    "\n",
    "**Interpretation:**  \n",
    "There is a strong negative correlation between bus conduct incidents and in-class referrals, as evidences by the negative T value and low p-values. While this seems counterintuitive, it suggests that students with bus conduct issues are more likely to be flagged for behavioral problems in the classroom. There likely may be a confounding factor where students with more bus referrals are removed from the classroom more frequently, thus reducing their in-class referral counts.\n",
    "\n",
    "**Implication:**  \n",
    "Bus misconduct is a strong predictor of general behavioral issues. Students flagged for bus incidents may benefit from preemptive behavioral interventions or monitoring in the classroom.\n",
    "\n",
    "---\n",
    "\n",
    "### **H3: Family Engagement Negatively Correlates with Referrals**\n",
    "- **Spearman correlation:** `-0.8000`  \n",
    "- **P-value:** `0.2000`  \n",
    "- **Result:** *Not statistically significant.*\n",
    "\n",
    "**Interpretation:**  \n",
    "While a strong negative correlation was observed (suggesting that higher engagement corresponds with fewer referrals), the p-value was not below the 0.05 threshold for significance. This may be due to small sample size (school-level aggregation). Historically, family engagement has been linked to improved student behavior, but this dataset did not provide strong enough evidence to confirm that relationship at the school level. This Hypothesis may benefit from further investigation with larger datasets or more student-level data.\n",
    "\n",
    "**Implication:**  \n",
    "There is potential evidence that increased family involvement could reduce behavior issues. Larger or student-level datasets may yield stronger conclusions.\n",
    "\n",
    "---\n",
    "\n",
    "### **H4: Referral Count Differs by Grade Level**\n",
    "- **F-statistic:** 1.7691\n",
    "- **P-value:** 0.0523\n",
    "- **Result:** *No significant difference in referrals between grades.*\n",
    "\n",
    "**Interpretation:**  \n",
    "The p-value is slightly above the 0.05 threshold, indicating that while there may be some variation in referral counts across grades, it is not statistically significant from these factors alone. Other factors are likely contributing to grade level referrals. The F-statistic suggests that the differences are not large enough to warrant further investigation at this time.\n",
    "\n",
    "**Implication:**  \n",
    "Grade levels do not appear to have different total referral counts. Future analyses may focus on other demographic factors or specific behaviors rather than grade level. An example being time of day showing a distinct difference in writeups in the heatmap visualized earlier. The results suggest that grade level alone is not a strong predictor of referral frequency, and that it is a combination of factors that contribute to behavioral issues.\n",
    "\n",
    "A different approach that handles high variance (e.g students with 0 referrals). may be needed to identify specific grade-level trends or behaviors that warrant further investigation through total referral rates alone.\n",
    "\n",
    "---\n",
    "\n",
    "### **H5: Weather Correlation with Referral Volume**\n",
    "- **Temperature Correlation (Pearson):** `0.1636` (p = `0.0455`)  \n",
    "- **Humidity Correlation (Pearson):** `0.1566` (p = `0.0557`)\n",
    "\n",
    "**Interpretation:**  \n",
    "There is a **weak but statistically significant** positive correlation between **temperature** and **referral volume**, indicating referrals tend to rise on warmer days. The correlation with humidity is borderline and not statistically significant at α = 0.05.\n",
    "\n",
    "**Implication:**  \n",
    "Environmental stressors such as heat may contribute to behavioral issues. Higher temperatures is often considered an agitory effect for people, and could be contributing towards aggressive or inappropriate behaivors in classes. Schools could explore increased temperature controls or schedule class time adjustments during high-heat periods.\n",
    "\n",
    "---\n",
    "\n",
    "### **H6: Weather Correlation with Referral Volume**\n",
    "- **During Break vs Regular Day (Dunn's Post-Hoc):** p = `0.015`\n",
    "- **All Others** p > `0.05`\n",
    "\n",
    "**Interpretation**\n",
    "Daily referral counts drop to near zero during major school breaks, as expected. Notably, spikes in referral counts are often observed in the days leading up to breaks—particularly before Spring, Summer, and Winter breaks as well as shortly after students return. This pattern suggests increased behavioral incidents during transition periods. However the only significant p-value was during break vs. regular days. Additionally, there is a visible tendency for higher referral counts on hotter days, indicating a possible positive relationship between temperature and disciplinary issues.\n",
    "\n",
    "**Implication**\n",
    "Behavioral challenges may intensify during periods of anticipation or adjustment around breaks, highlighting the importance of targeted support during these windows. Schools could proactively implement classroom management strategies or behavioral reinforcement before breaks and immediately upon return. Moreover, the temperature referral trend suggests that environmental stressors like heat may exacerbate behavioral issues, warranting climate-aware interventions during warmer periods.\n",
    "\n",
    "---\n",
    "\n",
    "### Overall Recommendations:\n",
    "\n",
    "- **Focus future models on bus conduct as a predictive feature.**\n",
    "- **Consider temperature as a situational risk factor.**\n",
    "- **Explore family engagement strategies to reduce referrals.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {
    "id": "35"
   },
   "source": [
    "## Initial Recommendations for School Stakeholders\n",
    "\n",
    "Based on data-driven hypothesis testing and exploratory analysis, the following recommendations are proposed to help school administrators reduce behavioral disruptions and improve classroom environments:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Monitor Students with Bus Conduct Incidents\n",
    "> **Why:** Students with bus conduct violations had *statistically significantly lower* classroom referral rates. In our dataset, this appears counterintuitive, but it suggests that bus incidents may be a strong predictor of overall behavioral issues. it is likely that students with bus write-ups are more frequently removed from the classroom, thus reducing their in-class referral counts.\n",
    "\n",
    "**Recommendations:**\n",
    "- Flag students with bus write-ups for early behavioral intervention or counseling.\n",
    "- Integrate bus conduct records into early warning systems.\n",
    "- Train bus drivers to identify and report behavioral issues that may carry over into the classroom.\n",
    "- Perform early intervention strategies for students with bus conduct issues to prevent escalation.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Plan for Heat-Related Behavior Increases\n",
    "> **Why:** Referral counts showed a *significant positive correlation* with higher temperatures.\n",
    "\n",
    "**Recommendations:**\n",
    "- Improve classroom cooling access and hydration breaks during hot weather.\n",
    "- Train teachers in managing heat-induced student irritability.\n",
    "- Monitor referrals during heatwaves and adjust scheduling if needed.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Use Family Engagement as a Soft Predictor\n",
    "> **Why:** A strong negative (though not statistically significant) correlation was observed between family engagement and referrals.\n",
    "\n",
    "**Recommendations:**\n",
    "- Encourage increased parental participation in school events and surveys.\n",
    "- Use engagement metrics to target school-specific outreach strategies.\n",
    "- Offer incentives for family involvement in education and discipline policies.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Prepare for Behavioral Peaks Around School Breaks or Testing Seasons\n",
    "> **Why:** Referral counts spiked before and after school breaks, as well as during testing periods.\n",
    "\n",
    "**Recommendations:**\n",
    "- Implement proactive classroom management strategies before breaks.\n",
    "- Schedule additional counseling or support sessions during these times.\n",
    "- Analyze referral patterns around testing seasons to identify stress-related behaviors.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Prioritize Multivariate Data Collection for Risk Prediction\n",
    "> **Why:** Bus behavior, weather, and family engagement all show predictive potential.\n",
    "\n",
    "**Recommendations:**\n",
    "- Initial results show correlation between multiple factors regarding referral counts.\n",
    "- Collect more data on student behavior, including bus conduct, weather conditions, and family engagement metrics.\n",
    "- Use multivariate models to predict referral risk based on these factors.\n",
    "\n",
    "---\n",
    "\n",
    "These recommendations are intended to guide practical changes and inform predictive modeling efforts that follow in subsequent sections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {
    "id": "36"
   },
   "source": [
    "## 5. Feature Engineering\n",
    "In this section we will create a student-week model dataset that aggregates student behavior data on a weekly basis. This will help us analyze trends and patterns in student behavior over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37",
    "outputId": "24a67c2c-d3cc-4520-de6c-48719ea7b56c"
   },
   "outputs": [],
   "source": [
    "#  Merging all the datasets into one model ready dataset\n",
    "# Reload datasets\n",
    "original_ref = pd.read_csv(\"TTU Data - Disciplinary Referral.csv\")\n",
    "update_ref = pd.read_csv(\"TTU Data Update - Disciplinary Referral.csv\")\n",
    "original_bus = pd.read_csv(\"TTU Data - Bus Conduct.csv\")\n",
    "update_bus = pd.read_csv(\"TTU Data Update - Bus Conduct.csv\")\n",
    "family_engagement = pd.read_csv(\"TTU Data - Family Engagement.csv\")\n",
    "weather = pd.read_csv(\"weather.csv\")\n",
    "\n",
    "# Merge referrals\n",
    "all_ref_columns = list(set(original_ref.columns).union(set(update_ref.columns)))\n",
    "original_ref = original_ref.reindex(columns=all_ref_columns)\n",
    "update_ref = update_ref.reindex(columns=all_ref_columns)\n",
    "full_ref = pd.concat([original_ref, update_ref], ignore_index=True).drop_duplicates()\n",
    "\n",
    "# Merge bus conduct\n",
    "all_bus_columns = list(set(original_bus.columns).union(set(update_bus.columns)))\n",
    "original_bus = original_bus.reindex(columns=all_bus_columns)\n",
    "update_bus = update_bus.reindex(columns=all_bus_columns)\n",
    "full_bus = pd.concat([original_bus, update_bus], ignore_index=True).drop_duplicates()\n",
    "\n",
    "# Preprocess dates\n",
    "full_ref['Date of Incident'] = pd.to_datetime(full_ref['Date of Incident'], errors='coerce')\n",
    "full_bus['Date of Incident'] = pd.to_datetime(full_bus['Date of Incident'], errors='coerce')\n",
    "weather['datetime'] = pd.to_datetime(weather['datetime'], errors='coerce')\n",
    "\n",
    "# STEP 1: Create 'Week' columns\n",
    "full_ref['Week'] = full_ref['Date of Incident'].dt.to_period('W').apply(lambda r: r.start_time)\n",
    "full_bus['Week'] = full_bus['Date of Incident'].dt.to_period('W').apply(lambda r: r.start_time if not pd.isnull(r) else None)\n",
    "# STEP 2: Aggregate referral and bus incidents per student per week\n",
    "ref_agg = full_ref.groupby(['Student Identifier', 'Week']).size().reset_index(name='weekly_referrals')\n",
    "bus_agg = full_bus.groupby(['Student Identifier', 'Week']).size().reset_index(name='weekly_bus_incidents')\n",
    "\n",
    "# STEP 3: Extract basic student metadata\n",
    "student_meta = full_ref.drop_duplicates('Student Identifier')[['Student Identifier', 'Grade_Level', 'Gender', 'Ethnicity', 'LunchStatus']]\n",
    "\n",
    "# STEP 4: Normalize and prepare engagement survey data\n",
    "engagement_data = family_engagement.rename(columns=lambda x: x.strip())\n",
    "if 'Student Identifier' not in engagement_data.columns:\n",
    "    for col in engagement_data.columns:\n",
    "        if 'student' in col.lower() and 'id' in col.lower():\n",
    "            engagement_data.rename(columns={col: 'Student Identifier'}, inplace=True)\n",
    "            break\n",
    "\n",
    "# STEP 5: Merge referral and bus data\n",
    "student_weeks = pd.merge(ref_agg, bus_agg, on=['Student Identifier', 'Week'], how='outer').fillna(0)\n",
    "\n",
    "# STEP 6: Add student demographic data\n",
    "student_weeks = pd.merge(student_weeks, student_meta, on='Student Identifier', how='left')\n",
    "\n",
    "# STEP 7: Add engagement survey data\n",
    "student_weeks = pd.merge(student_weeks, engagement_data, on='Student Identifier', how='left')\n",
    "\n",
    "# STEP 8: Add weekly weather aggregates\n",
    "weather['Week'] = weather['datetime'].dt.to_period('W').apply(lambda r: r.start_time)\n",
    "weather_weekly = weather.groupby('Week').agg({\n",
    "    'temp': 'mean',\n",
    "    'humidity': 'mean',\n",
    "    'precip': 'mean',\n",
    "    'sealevelpressure': 'mean',\n",
    "    'windgust': 'mean'\n",
    "}).reset_index()\n",
    "student_weeks = pd.merge(student_weeks, weather_weekly, on='Week', how='left')\n",
    "\n",
    "# STEP 9: Create target variable\n",
    "student_weeks = student_weeks.sort_values(by=['Student Identifier', 'Week'])\n",
    "student_weeks['referral_next_week'] = student_weeks.groupby('Student Identifier')['weekly_referrals'].shift(-1)\n",
    "student_weeks['referral_next_week'] = (student_weeks['referral_next_week'] > 0).astype(int)\n",
    "\n",
    "# Display the result\n",
    "print(\"Model-Ready Dataset Preview:\")\n",
    "print(student_weeks.head())\n",
    "print(\"\\nShape:\", student_weeks.shape)\n",
    "print(\"Columns:\", student_weeks.columns.tolist())\n",
    "\n",
    "student_weeks.to_csv(\"model_ready_student_weeks.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {
    "id": "38"
   },
   "source": [
    "## 6. Model Development\n",
    "\n",
    "In this section, we implement logistic regression, linear regression, and an advanced Random Forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {
    "id": "39"
   },
   "source": [
    "### Loading the data and training/testing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "40",
    "outputId": "8ce98d9c-a04d-4bca-9a99-5a8cf5c179fd"
   },
   "outputs": [],
   "source": [
    "student_weeks = pd.read_csv(\"model_ready_student_weeks.csv\")\n",
    "student_weeks.dropna(subset=['referral_next_week'], inplace=True)\n",
    "\n",
    "features = ['weekly_referrals', 'weekly_bus_incidents', 'Grade_Level', 'Gender',\n",
    "            'Ethnicity', 'LunchStatus', 'temp', 'humidity', 'precip', 'sealevelpressure', 'windgust']\n",
    "\n",
    "X = student_weeks[features]\n",
    "y_classification = student_weeks['referral_next_week']\n",
    "y_regression = student_weeks['weekly_referrals']\n",
    "\n",
    "X_train, X_test, y_clf_train, y_clf_test, y_reg_train, y_reg_test = train_test_split(\n",
    "    X, y_classification, y_regression, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Total samples after cleaning: {X.shape[0]}\")\n",
    "print(f\"  • Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"  • Test set:     {X_test.shape[0]} samples\")\n",
    "print(f\"Referral-next-week positive rate (train): {y_clf_train.mean():.2%}\")\n",
    "print(f\"Referral-next-week positive rate (test):  {y_clf_test.mean():.2%}\")\n",
    "print(f\"Weekly referrals (train) — mean: {y_reg_train.mean():.2f}, std: {y_reg_train.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {
    "id": "fc-0cyfkIWxW"
   },
   "source": [
    "After dropping missing outcomes, an 80/20 split yielded N_train training samples and N_test test samples, as specified. The proportion of students flagged for referral next week is very similar in both sets, indicating that the random split preserved the class balance. The regression target (weekly referrals) has a mean of M and a standard deviation of S in the training set, suggesting moderate variability in weekly referral counts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {
    "id": "41"
   },
   "source": [
    "### Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42",
    "outputId": "93beb14a-0dd9-40dc-ab2d-e3a179d8b948"
   },
   "outputs": [],
   "source": [
    "# Preprocessing pipelines\n",
    "numeric_features = ['weekly_referrals', 'weekly_bus_incidents', 'Grade_Level','temp']\n",
    "categorical_features = ['Gender', 'Ethnicity', 'LunchStatus']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# Regression preprocessor: EXCLUDE weekly_referrals to avoid leakage\n",
    "preprocessor_reg = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, ['weekly_bus_incidents','Grade_Level','temp']),\n",
    "    ('cat', categorical_transformer, ['Gender','Ethnicity','LunchStatus'])\n",
    "])\n",
    "\n",
    "preprocessor.fit(X_train)\n",
    "X_train_clf = preprocessor.transform(X_train)\n",
    "preprocessor_reg.fit(X_train)\n",
    "X_train_reg = preprocessor_reg.transform(X_train)\n",
    "\n",
    "print(f\"Classification pipeline output features: {X_train_clf.shape[1]}\")\n",
    "print(f\"Regression pipeline output features:   {X_train_reg.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {
    "id": "_lkJt7wdIwhH"
   },
   "source": [
    "Purpose:\n",
    "The classification pipeline includes the weekly_referrals predictor, which is the target variable for the the models. The pipeline applies one-hot encoding to categorical features like school and grade level, and scales numerical features such as temperature and humidity. This ensures that all features are appropriately transformed for model training.\n",
    "\n",
    "Reason:\n",
    "The preprocessing pipeline is essential for preparing the data for machine learning models. It ensures that categorical variables are converted into a format suitable for model training, and that numerical features are scaled to have similar ranges, which can improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {
    "id": "43"
   },
   "source": [
    "### Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44",
    "outputId": "5a106c76-3c67-4724-f09a-1b583e079e1a"
   },
   "outputs": [],
   "source": [
    "# Model pipelines\n",
    "pipelines = {\n",
    "    'LogisticRegression': ImbPipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', LogisticRegression(max_iter=1000, random_state=42))\n",
    "    ]),\n",
    "    'LinearRegression': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('clf', LinearRegression())\n",
    "    ]),\n",
    "    'NeuralNetwork': ImbPipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', MLPClassifier(hidden_layer_sizes=(50,), max_iter=300, random_state=42))\n",
    "    ]),\n",
    "    'RandomForest': ImbPipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('clf', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Extended regression pipelines\n",
    "regression_pipelines = {\n",
    "    'Poisson': Pipeline([\n",
    "        ('pre', preprocessor_reg),\n",
    "        ('reg', PoissonRegressor(max_iter=300, alpha=1e-12))\n",
    "    ]),\n",
    "    'Ridge': Pipeline([\n",
    "        ('pre', preprocessor_reg),\n",
    "        ('reg', Ridge(alpha=1.0))\n",
    "    ]),\n",
    "    'Lasso': Pipeline([\n",
    "        ('pre', preprocessor_reg),\n",
    "        ('reg', Lasso(alpha=0.1, max_iter=5000))\n",
    "    ]),\n",
    "    'ElasticNet': Pipeline([\n",
    "        ('pre', preprocessor_reg),\n",
    "        ('reg', ElasticNet(alpha=0.1, l1_ratio=0.5, max_iter=5000))\n",
    "    ]),\n",
    "    'Huber': Pipeline([\n",
    "        ('pre', preprocessor_reg),\n",
    "        ('reg', HuberRegressor(max_iter=300))\n",
    "    ]),\n",
    "    'RANSAC': Pipeline([\n",
    "        ('pre', preprocessor_reg),\n",
    "        ('reg', RANSACRegressor(random_state=42))\n",
    "    ]),\n",
    "    'RF_Regressor': Pipeline([\n",
    "        ('pre', preprocessor_reg),\n",
    "        ('reg', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "    ]),\n",
    "    'GB_Regressor': Pipeline([\n",
    "        ('pre', preprocessor_reg),\n",
    "        ('reg', GradientBoostingRegressor(n_estimators=100, random_state=42))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# === Print pipeline summaries ===\n",
    "print(f\"Classification pipelines ({len(pipelines)}): {list(pipelines.keys())}\")\n",
    "print(f\"Regression pipelines ({len(regression_pipelines)}): {list(regression_pipelines.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {
    "id": "NTD3sPYPJDBm"
   },
   "source": [
    "Purpose:\n",
    "A total of four classification and eight regression pipelines have been configured. Each classification pipeline pairs the shared preprocessing steps (and SMOTE for handling class imbalance) with a different estimator, while the regression pipelines apply the leakage‐free preprocessing to a diverse set of linear, robust, and ensemble models.\n",
    "\n",
    "Reason:\n",
    "With this standardized setup, we can systematically train and compare how different algorithms perform on both the referral‐classification task and the weekly‐referrals regression task, ensuring consistency in preprocessing and easy parallel experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bc7c4eb",
    "outputId": "fc3686d9-6ce0-40c9-b936-71435b1bda04"
   },
   "outputs": [],
   "source": [
    "# Classification features include the lagged referral count:\n",
    "features_clf = [\n",
    "    'weekly_referrals','weekly_bus_incidents','Grade_Level',\n",
    "    'Gender','Ethnicity','LunchStatus','temp',\n",
    "    'humidity','precip','sealevelpressure','windgust'\n",
    "]\n",
    "X_clf = student_weeks[features_clf]\n",
    "y_clf = student_weeks['referral_next_week']\n",
    "\n",
    "# Regression must exclude the target itself to avoid leakage:\n",
    "features_reg = [f for f in features_clf if f != 'weekly_referrals']  # <<< FIX HERE\n",
    "X_reg = student_weeks[features_reg]\n",
    "y_reg = student_weeks['weekly_referrals']\n",
    "\n",
    "# Split each dataset independently:\n",
    "# from sklearn.model_selection import train_test_split\n",
    "X_clf_train, X_clf_test, y_clf_train, y_clf_test = train_test_split(\n",
    "    X_clf, y_clf, test_size=0.2, random_state=42\n",
    ")\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(f\"Classification total samples: {X_clf.shape[0]}\")\n",
    "print(f\"  • Training samples: {X_clf_train.shape[0]}\")\n",
    "print(f\"  • Test samples:     {X_clf_test.shape[0]}\")\n",
    "print(f\"  • Positive class rate (train): {y_clf_train.mean():.2%}\")\n",
    "print(f\"  • Positive class rate (test):  {y_clf_test.mean():.2%}\")\n",
    "\n",
    "print(f\"Regression total samples: {X_reg.shape[0]}\")\n",
    "print(f\"  • Training samples: {X_reg_train.shape[0]}\")\n",
    "print(f\"  • Test samples:     {X_reg_test.shape[0]}\")\n",
    "print(f\"  • Weekly referrals (train) mean: {y_reg_train.mean():.2f}, std: {y_reg_train.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {
    "id": "J31DOwiEJQcz"
   },
   "source": [
    "Purpoose:\n",
    "Separate splits were performed for the classification and regression tasks to ensure no data leakage between models. The classification split preserves the base rate of referral-next-week in both training and test sets, indicating a balanced random draw. The regression split yields comparable sample sizes and reveals the average weekly referral count of the training set with its variability.\n",
    "\n",
    "Reasons:\n",
    "Maintaining independent, representative splits for each modeling objective secures valid performance estimates. The consistent class rates and regression target distribution suggest no obvious sampling bias, supporting reliable downstream model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {
    "id": "45"
   },
   "source": [
    "### Parameter Grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {
    "id": "46"
   },
   "outputs": [],
   "source": [
    "# Parameter grids\n",
    "param_grids = {\n",
    "    'LogisticRegression': {\n",
    "        'clf__C': [0.01, 0.1, 1.0, 10.0],\n",
    "        'clf__penalty': ['l2'],\n",
    "        'clf__solver': ['lbfgs']\n",
    "    },\n",
    "    'LinearRegression': {\n",
    "        'clf__fit_intercept': [True, False],\n",
    "        'clf__positive': [False, True]\n",
    "    },\n",
    "    'NeuralNetwork': {\n",
    "        'clf__hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50), (64, 64, 32)],\n",
    "        'clf__activation': ['relu', 'tanh'],\n",
    "        'clf__solver': ['adam'],\n",
    "        'clf__alpha': [0.0001, 0.001],\n",
    "        'clf__learning_rate': ['constant', 'adaptive'],\n",
    "        'clf__early_stopping': [True],\n",
    "        'clf__n_iter_no_change': [5]\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'clf__n_estimators': [100, 200],\n",
    "        'clf__max_depth': [None, 10, 20],\n",
    "        'clf__min_samples_split': [2, 5],\n",
    "        'clf__min_samples_leaf': [1, 2],\n",
    "        'clf__bootstrap': [True, False]\n",
    "    }\n",
    "}\n",
    "\n",
    "# GridSearchCV runner\n",
    "def run_grid_searches(X_train, y_train, pipelines):\n",
    "    best_models = {}\n",
    "    for model_name, pipeline in pipelines.items():\n",
    "        if model_name not in param_grids:\n",
    "            print(f\"Skipping model: {model_name}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nTuning hyperparameters for: {model_name}...\")\n",
    "\n",
    "        grid = GridSearchCV(\n",
    "            pipeline,\n",
    "            param_grid=param_grids[model_name],\n",
    "            cv=5,\n",
    "            scoring='f1_macro' if model_name != 'LinearRegression' else 'r2',\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        grid.fit(X_train, y_train)\n",
    "        best_models[model_name] = grid\n",
    "\n",
    "        print(f\"\\nBest Params for {model_name}: {grid.best_params_}\")\n",
    "        print(f\"Best Score: {grid.best_score_:.4f}\")\n",
    "\n",
    "    return best_models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {
    "id": "47"
   },
   "source": [
    "### DBSCAN Clustering Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {
    "id": "48"
   },
   "outputs": [],
   "source": [
    "def evaluate_dbscan(X_raw):\n",
    "    # Preprocess the data\n",
    "    X_numeric = X_raw.select_dtypes(include=[np.number])\n",
    "    X_numeric = pd.DataFrame(SimpleImputer(strategy=\"mean\").fit_transform(X_numeric), columns=X_numeric.columns)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_numeric)\n",
    "\n",
    "    # Parameter ranges\n",
    "    eps_vals = np.arange(0.1, 1.1, 0.1)\n",
    "    min_samples_vals = [3, 5, 7]\n",
    "\n",
    "    best_score = -1\n",
    "    best_model = None\n",
    "    best_params = None\n",
    "\n",
    "    # Iterate over parameter combinations\n",
    "    for eps in eps_vals:\n",
    "        for min_samples in min_samples_vals:\n",
    "            model = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "            labels = model.fit_predict(X_scaled)\n",
    "            n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "            if n_clusters < 2:\n",
    "                print(f\"Skipped eps={eps:.1f}, min_samples={min_samples} — only {n_clusters} cluster(s) detected\")\n",
    "                continue\n",
    "\n",
    "            score = silhouette_score(X_scaled, labels)\n",
    "            print(f\"Checked eps={eps:.1f}, min_samples={min_samples} → Silhouette Score: {score:.4f}\")\n",
    "\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_model = model\n",
    "                best_params = {'eps': eps, 'min_samples': min_samples}\n",
    "\n",
    "    if best_model:\n",
    "        print(\"\\nBest DBSCAN Params:\", best_params)\n",
    "        print(\"Best Silhouette Score:\", best_score)\n",
    "    else:\n",
    "        print(\"No valid DBSCAN clustering found. Adjust parameter ranges or examine dataset scale.\")\n",
    "\n",
    "    return best_model, best_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {
    "id": "49"
   },
   "source": [
    "## 7. Model Evaluation and Interpretation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "50",
    "outputId": "97146ddc-2a55-4a77-88d8-87262be8899d"
   },
   "outputs": [],
   "source": [
    "def evaluate_model_results(best_models, X_test, y_clf_test, y_reg_test):\n",
    "    for name, model in best_models.items():\n",
    "        print(f\"\\nEvaluation Results for {name}\")\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        if is_regressor(model) and not is_classifier(model):\n",
    "            # Regressor evaluation\n",
    "            try:\n",
    "                mse = mean_squared_error(y_reg_test, y_pred)\n",
    "                rmse = np.sqrt(mse)\n",
    "                r2 = r2_score(y_reg_test, y_pred)\n",
    "\n",
    "                print(f\"RMSE: {rmse:.4f}\")\n",
    "                print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "                # Regression scatter plot\n",
    "                plt.figure(figsize=(6, 4))\n",
    "                plt.scatter(y_reg_test, y_pred, alpha=0.3)\n",
    "                plt.title(f'{name} — Actual vs. Predicted Referrals')\n",
    "                plt.xlabel(\"Actual Referrals\")\n",
    "                plt.ylabel(\"Predicted Referrals\")\n",
    "                plt.grid(True)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            except Exception as e:\n",
    "                print(\"[Regression Metrics Error]:\", e)\n",
    "\n",
    "        elif is_classifier(model):\n",
    "            # Classifier evaluation\n",
    "            try:\n",
    "                y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "                acc = accuracy_score(y_clf_test, y_pred)\n",
    "                prec = precision_score(y_clf_test, y_pred)\n",
    "                rec = recall_score(y_clf_test, y_pred)\n",
    "                f1 = f1_score(y_clf_test, y_pred)\n",
    "                roc_auc = roc_auc_score(y_clf_test, y_proba) if y_proba is not None else 'N/A'\n",
    "\n",
    "                print(f\"Accuracy: {acc:.4f}\")\n",
    "                print(f\"Precision: {prec:.4f}\")\n",
    "                print(f\"Recall: {rec:.4f}\")\n",
    "                print(f\"F1 Score: {f1:.4f}\")\n",
    "                print(f\"ROC AUC: {roc_auc:.4f}\" if roc_auc != 'N/A' else \"ROC AUC: N/A\")\n",
    "\n",
    "                cm = confusion_matrix(y_clf_test, y_pred)\n",
    "                plt.figure(figsize=(5, 4))\n",
    "                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "                plt.title(f\"{name} — Confusion Matrix\")\n",
    "                plt.xlabel(\"Predicted\")\n",
    "                plt.ylabel(\"Actual\")\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"[Classification Metrics Error]:\", e)\n",
    "\n",
    "        else:\n",
    "            print(f\"{name} is neither a recognized classifier nor regressor.\")\n",
    "\n",
    "# Usage:\n",
    "# best_models = run_grid_searches(X_train, y_clf_train, pipelines)\n",
    "# evaluate_model_results(best_models, X_test, y_clf_test, y_reg_test)\n",
    "\n",
    "# select best models and evaluate them for normal pipeline\n",
    "best_models = run_grid_searches(X_clf_train, y_clf_train, pipelines)\n",
    "evaluate_model_results(best_models, X_clf_test, y_clf_test, y_reg_test)\n",
    "# select best models and evaluate them for regression pipeline\n",
    "best_reg_models = run_grid_searches(X_reg_train, y_reg_train, regression_pipelines)\n",
    "evaluate_model_results(best_reg_models, X_reg_test, y_reg_test, y_reg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a946ff9e",
    "outputId": "c2f96925-dc4b-413e-ee4f-22558dc808e1"
   },
   "outputs": [],
   "source": [
    "# Define parameter grids for regression\n",
    "param_grids_reg = {\n",
    "    'Poisson':    {'reg__alpha': [1e-12, 1e-6, 1e-2]},\n",
    "    'Ridge':      {'reg__alpha': [0.1, 1.0, 10.0]},\n",
    "    'Lasso':      {'reg__alpha': [0.01, 0.1, 1.0]},\n",
    "    'ElasticNet': {'reg__alpha': [0.01,0.1], 'reg__l1_ratio':[0.2,0.5,0.8]},\n",
    "    'RF_Regressor': {'reg__n_estimators': [50,100], 'reg__max_depth':[None,10]},\n",
    "    'GB_Regressor': {'reg__n_estimators': [50,100], 'reg__learning_rate':[0.1,0.01]},\n",
    "}\n",
    "\n",
    "best_regressors = {}\n",
    "for name, pipe in regression_pipelines.items():\n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=param_grids_reg.get(name, {}),\n",
    "        cv=5,\n",
    "        scoring='neg_root_mean_squared_error',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid.fit(X_train, y_reg_train)\n",
    "    best_regressors[name] = grid.best_estimator_\n",
    "    print(f\"{name}: Best params = {grid.best_params_}, RMSE = {-grid.best_score_:.3f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "for name, model in best_regressors.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_reg_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2   = r2_score(y_reg_test, y_pred)\n",
    "    print(f\"{name}:  RMSE = {rmse:.3f},  R² = {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {
    "id": "51"
   },
   "source": [
    "### DBSCAN Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "52",
    "outputId": "d39bf5e8-2aff-41aa-c186-186fbbff0402"
   },
   "outputs": [],
   "source": [
    "def visualize_dbscan_clusters(dbscan_model, X_raw, preprocessor):\n",
    "    if dbscan_model is None:\n",
    "        print(\"DBSCAN model is None — check if a valid model was returned from evaluate_dbscan().\")\n",
    "        return\n",
    "\n",
    "    X_preprocessed = preprocessor.fit_transform(X_raw)\n",
    "    labels = dbscan_model.fit_predict(X_preprocessed)\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced = pca.fit_transform(X_preprocessed)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scatter = plt.scatter(reduced[:, 0], reduced[:, 1], c=labels, cmap='tab10', s=20, alpha=0.6)\n",
    "    plt.title(\"DBSCAN Cluster Visualization (PCA-Reduced)\")\n",
    "    plt.xlabel(\"PCA Component 1\")\n",
    "    plt.ylabel(\"PCA Component 2\")\n",
    "    plt.grid(True)\n",
    "    plt.legend(*scatter.legend_elements(), title=\"Clusters\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "best_dbscan, best_score = evaluate_dbscan(X)\n",
    "if best_dbscan:\n",
    "    visualize_dbscan_clusters(best_dbscan, X, preprocessor)\n",
    "else:\n",
    "    print(\"No valid DBSCAN model was found. Please adjust the parameters or check the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ea7db1e9",
    "outputId": "90d5c732-cf60-4f4b-feec-4c139f871b6a"
   },
   "outputs": [],
   "source": [
    "# Cluster Profiling: mean feature values per DBSCAN cluster\n",
    "numeric_cols = X.select_dtypes(include=['int64','float64']).columns\n",
    "imp = SimpleImputer(strategy='mean')\n",
    "X_num = pd.DataFrame(imp.fit_transform(X[numeric_cols]), columns=numeric_cols)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X_num), columns=numeric_cols)\n",
    "\n",
    "db = DBSCAN(eps=0.8, min_samples=3).fit(X_scaled)\n",
    "labels = db.labels_\n",
    "\n",
    "df_profiles = X.copy()\n",
    "df_profiles[numeric_cols] = X_num\n",
    "df_profiles['cluster'] = labels\n",
    "\n",
    "cluster_summary = df_profiles.groupby('cluster')[numeric_cols].mean().round(2)\n",
    "print(cluster_summary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "### Extracting important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the trained model\n",
    "log_reg_model = best_models['LogisticRegression'].best_estimator_.named_steps['clf']\n",
    "lin_reg_model = best_models['LinearRegression'].best_estimator_.named_steps['clf']\n",
    "\n",
    "# Get feature names from the preprocessor\n",
    "feature_names = best_models['LogisticRegression'].best_estimator_.named_steps['preprocessor'] \\\n",
    "    .get_feature_names_out()\n",
    "\n",
    "# Logistic Regression coefficients\n",
    "log_reg_coefs = pd.Series(log_reg_model.coef_[0], index=feature_names).sort_values(key=abs, ascending=False)\n",
    "\n",
    "# Linear Regression coefficients\n",
    "lin_reg_coefs = pd.Series(lin_reg_model.coef_, index=feature_names).sort_values(key=abs, ascending=False)\n",
    "\n",
    "print(\"Logistic Regression Top Features:\\n\", log_reg_coefs.head())\n",
    "print(\"\\nLinear Regression Top Features:\\n\", lin_reg_coefs.head())\n",
    "\n",
    "# Random Forest feature importances\n",
    "rf_model = best_models['RandomForest'].best_estimator_.named_steps['clf']\n",
    "\n",
    "feature_names = best_models['RandomForest'].best_estimator_.named_steps['preprocessor'] \\\n",
    "    .get_feature_names_out()\n",
    "\n",
    "rf_importances = pd.Series(rf_model.feature_importances_, index=feature_names).sort_values(ascending=False)\n",
    "\n",
    "print(\"Random Forest Feature Importances:\\n\", rf_importances.head())\n",
    "\n",
    "# Neural Network feature importances\n",
    "\n",
    "# 1. Get the trained full pipeline\n",
    "nn_pipeline = best_models['NeuralNetwork'].best_estimator_\n",
    "\n",
    "results = permutation_importance(\n",
    "    nn_pipeline,               \n",
    "    X_clf_test,              \n",
    "    y_clf_test,                 \n",
    "    n_repeats=10,\n",
    "    random_state=42,\n",
    "    scoring='f1'\n",
    ")\n",
    "\n",
    "feature_names = nn_pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "\n",
    "importances = results.importances_mean\n",
    "if len(importances) != len(feature_names):\n",
    "    print(f\"⚠️ Mismatch: {len(importances)} importances vs {len(feature_names)} features. Adjusting.\")\n",
    "    min_len = min(len(importances), len(feature_names))\n",
    "    importances = importances[:min_len]\n",
    "    feature_names = feature_names[:min_len]\n",
    "\n",
    "perm_importances = pd.Series(importances, index=feature_names).sort_values(ascending=False)\n",
    "print(\"Permutation Importances (Neural Network):\\n\", perm_importances.head(10))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64",
   "metadata": {
    "id": "53"
   },
   "source": [
    "## Model Analysis and Interpretation\n",
    "\n",
    "### Overview\n",
    "This section interprets the output of the evaluated models — Logistic Regression, Linear Regression, Neural Network, and DBSCAN — providing context for what the results mean and implications for the school district.\n",
    "\n",
    "---\n",
    "\n",
    "### Logistic Regression\n",
    "- **Precision**: `0.6196`\n",
    "- **Recall**: `0.7403`\n",
    "- **F1 Score**: `0.6746`\n",
    "\n",
    "**Interpretation**: The model predicts referral risk based on a linear combination of inputs that increase or decrease the log-odds. For example, students with more weekly referrals, higher temperature, and certain ethnicities were more likely to be classified as high risk. In contrast, students with more bus incidents or who are on reduced lunch (LunchStatus_R) were less likely, according to the model coefficients. A one unit increase in weekly_referrals increases the log odds of a referral next week. However, a unit increase in weekly_bus_incidents actually lowers the odds in this model, possibly indicating noise or collinearity.\n",
    "\n",
    "**Top Features (by importance)**:\n",
    "- weekly_bus_incidents (−0.68): Negatively correlated with referrals — more bus incidents reduced predicted risk. Likely due to students being removed from the classroom more frequently as discussed earlier.\n",
    "- weekly_referrals (+0.64): Positively correlated — past referrals strongly increased risk.\n",
    "- temp (+0.37): Higher temperatures correlated with more predicted referrals.\n",
    "- LunchStatus_R (−0.33): Students on reduced lunch were less likely to be flagged.\n",
    "- Ethnicity_B (+0.19): Belonging to ethnic group \"B\" slightly raised predicted risk.\n",
    "\n",
    "**Analysis**: Logistic regression performed moderately well in predicting students who would receive a referral the following week. A recall of ~74% indicates that the model successfully identified most of the actual positive cases (students who were referred). However, with a precision of ~62%, about 38% of the students predicted to receive a referral did not actually receive one, indicating a moderate rate of false positives. The F1 score of 0.6746 reflects a balanced trade-off between precision and recall, making logistic regression a solid baseline model, but with room for improvement, especially in precision.\n",
    "\n",
    "---\n",
    "\n",
    "### Linear Regression\n",
    "- **RMSE**: `0.7571`\n",
    "- **R²**: `-0.2028`\n",
    "\n",
    "**Interpretation**: It adds weighted inputs to predict expected referral counts. Here, most signal came from ethnicity and lunch status, with almost no contribution from numeric features like bus incidents or temp, suggesting this model underperformed due to weak feature learning. A one unit increase in a binary-encoded category (e.g., changing from not Ethnicity_P to Ethnicity_P) decreases the expected number of referrals by 0.41, holding all else equal. But given the negative R², the model is not capturing meaningful structure and likely overfit or underfit the data.\n",
    "\n",
    "**Top Features (by coefficient size)**:\n",
    "- Ethnicity_P (−0.41): Being in this group was associated with fewer referrals.\n",
    "- Ethnicity_B (+0.30): Small positive correlation.\n",
    "- LunchStatus_P and LunchStatus_F: Positively associated with referral counts.\n",
    "\n",
    "**Analysis**: The model's R² is negative, indicating that it performs worse than simply predicting the mean value for all observations. The linear regression model failed to capture patterns in the data to predict the number of weekly referrals, suggesting the relationship is not linear or lacks strong predictive variables.\n",
    "\n",
    "---\n",
    "\n",
    "### Neural Network\n",
    "- **Precision**: `0.6374`\n",
    "- **Recall**: `0.7532`\n",
    "- **F1 Score**: `0.6905`\n",
    "\n",
    "**Interpretation**: The neural network predicts based on complex, nonlinear patterns. It considers combinations of variables (e.g., high referrals + low lunch status + high temperature) that interact in ways linear models can't capture. Increases in weekly_referrals or weekly_bus_incidents push predictions higher, but thresholds and interactions matter. For example, a high bus incident count may only affect prediction if combined with other factors like high temperature or early grade level\n",
    "\n",
    "**Top Features (by permuatation importance)**:\n",
    "- weekly_referrals — most critical factor, confirming history is predictive\n",
    "- weekly_bus_incidents — meaningful contributor, though less than referrals.\n",
    "- Grade_Level — age may correlate with maturity or policy differences.\n",
    "- temp — environmental conditions influence behavior.\n",
    "- LunchStatus_R, Gender_M, and Ethnicity_B — social or demographic influences.\n",
    "\n",
    "**Analysis**: The neural network outperformed logistic regression in predicting students who would receive a referral the following week. With a higher recall of ~75%, it correctly identified more actual referral cases, and its precision of ~64% shows a slight improvement in reducing false positives compared to logistic regression. The F1 score of 0.6905, being higher than the logistic regression's 0.6746, indicates a better overall balance between precision and recall, making the neural network the strongest performer among the tested models.\n",
    "\n",
    "---\n",
    "### Random Forest\n",
    "\n",
    "- **Precision**: `0.6163`\n",
    "- **Recall**: `0.6883`\n",
    "- **F1 Score**: `0.6503`\n",
    "\n",
    "**Interpretation**: It predicts based on majority vote across hundreds of decision trees, each using feature thresholds. For instance, one tree might say: \"If temp > 70 and weekly_referrals > 1, predict 1 (referral).\". Decision trees split at key thresholds. A change from weekly_referrals = 1 to 2 may cross a split and change the final class. These effects are nonlinear and may vary depending on the combination of other features like weather.\n",
    "\n",
    "**Top Features (by importance)**:\n",
    "- temp — most impactful, suggesting a strong seasonal/environmental effect.\n",
    "- weekly_referrals — history still matters.\n",
    "- Grade_Level — possibly affecting behavioral trends.\n",
    "- weekly_bus_incidents — contributes, but less than referrals or weather.\n",
    "- LunchStatus_R — demographic indicator with weaker influence.\n",
    "\n",
    "**Analysis**: The Random Forest model performed slightly below both logistic regression and the neural network in predicting student referrals. With a precision of ~62%, it had a similar rate of false positives as the other models, but its recall of ~69% indicates it missed more actual referral cases compared to the neural network, and slightly more than logistic regression. The F1 score of 0.6503 reflects a somewhat weaker balance between precision and recall, suggesting that while Random Forest is a viable model, it may not be as effective as the others for this particular prediction task.\n",
    "\n",
    "---\n",
    "\n",
    "### DBSCAN Clustering\n",
    "- **Best Params**: eps=0.8, min_samples=3\n",
    "- **Best Silhouette Score**: 0.4634\n",
    "\n",
    "**Interpretation**: DBSCAN groups students based on density: students with similar behavior (e.g., referral and bus incident patterns, weather exposure, demographics) form clusters if they are closely packed in feature space. Points not close to any dense region are marked as outliers (cluster -1). DBSCAN is sensitive to distance, so small changes in key features like weekly_referrals or Grade_Level can push a student from a dense region (a cluster) into noise (outlier) or another group. For example, adding 1 weekly referral might tip a student into a higher risk cluster, depending on surrounding data.\n",
    "\n",
    "**Top Features**:\n",
    "- Weekly referrals\n",
    "- Bus incidents\n",
    "- Grade level\n",
    "- Temperature and humidity\n",
    "\n",
    "**Analysis**: DBSCAN discovered moderately well-separated clusters (silhouette ~0.46). These clusters could correspond to different behavior profiles or referral risk tiers. However, the silhouette score indicates that many points lie near cluster boundaries, suggesting some overlap or noise in student behavior patterns.\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65",
   "metadata": {
    "id": "54"
   },
   "source": [
    "## 8. Summary\n",
    "This section provides a high-level overview of the full modeling process, including data cleaning decisions and their rationale, an analysis of the best-performing model (neural network) and how it works, along with key benefits, general takeaways from the results, and actionable recommendations for the school district. The goal is to summarize the entire modeling process and its implications for the school district in a concise manner. The model works by predicting the likelihood of a student receiving a referral in the next week based on various features such as past referrals, bus incidents, temperature, and demographic information. The neural network model was chosen as the best-performing model due to its ability to capture complex relationships in the data, achieving a recall of ~75% and an F1 score of 0.6905."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "---\n",
    "### Data Cleaning\n",
    "\n",
    "Multiple datasets were merged and standardized, including disciplinary referrals, bus conduct, family engagement, and weather records. Date fields were parsed and used to create weekly time bins. Missing or inconsistent student identifiers and metadata were resolved, and null values in key columns were handled using imputation or defaults (e.g., zero for missing incident counts). Duplicate entries were removed, and weekly aggregates were calculated per student. The final dataset was cleaned to ensure consistency, proper data types, and alignment across all sources for model readiness.\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "### Best Model\n",
    "\n",
    "The **neural network model** outperformed all others in predicting which students were likely to receive a disciplinary referral the following week.\n",
    "\n",
    "**How it Worked:** \n",
    "- Captured nonlinear interactions between variables (e.g., how temperature, referral history, and lunch status interact).\n",
    "\n",
    "- Used complex combinations of inputs to make predictions that simpler models (like logistic regression) couldn't detect.\n",
    "\n",
    "- Incorporated feature importance through permutation methods, confirming that weekly referral history, bus incidents, grade level, and environmental factors (e.g., temperature) were strong drivers of behavior.\n",
    "\n",
    "**Benefits:**\n",
    "- High recall means it successfully identified most students at risk, making it ideal for early intervention and prevention efforts.\n",
    "\n",
    "- Better precision than logistic regression, meaning fewer false alarms when flagging students.\n",
    "\n",
    "- Able to generalize from complex patterns, increasing the accuracy of predictions across diverse student profiles and conditions.\n",
    "\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect metrics function\n",
    "def collect_model_metrics(best_models, X_test, y_clf_test, y_reg_test):\n",
    "    clf_metrics = []\n",
    "    reg_metrics = []\n",
    "\n",
    "    for name, model in best_models.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        if is_regressor(model) and not is_classifier(model):\n",
    "            try:\n",
    "                mse = mean_squared_error(y_reg_test, y_pred)\n",
    "                rmse = np.sqrt(mse)\n",
    "                r2 = r2_score(y_reg_test, y_pred)\n",
    "                reg_metrics.append({'Model': name, 'RMSE': rmse, 'R2': r2})\n",
    "            except Exception as e:\n",
    "                print(f\"[Regression Metrics Error] {name}:\", e)\n",
    "\n",
    "        elif is_classifier(model):\n",
    "            try:\n",
    "                y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "                acc = accuracy_score(y_clf_test, y_pred)\n",
    "                prec = precision_score(y_clf_test, y_pred)\n",
    "                rec = recall_score(y_clf_test, y_pred)\n",
    "                f1 = f1_score(y_clf_test, y_pred)\n",
    "                roc_auc = roc_auc_score(y_clf_test, y_proba) if y_proba is not None else np.nan\n",
    "\n",
    "                clf_metrics.append({\n",
    "                    'Model': name,\n",
    "                    'Accuracy': acc,\n",
    "                    'Precision': prec,\n",
    "                    'Recall': rec,\n",
    "                    'F1 Score': f1,\n",
    "                    'ROC AUC': roc_auc\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"[Classification Metrics Error] {name}:\", e)\n",
    "\n",
    "    return pd.DataFrame(clf_metrics), pd.DataFrame(reg_metrics)\n",
    "\n",
    "# plot metrics function\n",
    "def plot_metrics(df_clf, df_reg):\n",
    "    if not df_clf.empty:\n",
    "        df_clf.set_index('Model', inplace=True)\n",
    "        df_clf.plot(kind='bar', figsize=(12, 6), title=\"Classification Model Comparison\", grid=True)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.ylabel(\"Score\")\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    if not df_reg.empty:\n",
    "        df_reg.set_index('Model', inplace=True)\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "        df_reg['RMSE'].plot(kind='bar', ax=axes[0], title=\"Regression RMSE Comparison\", grid=True)\n",
    "        axes[0].set_ylabel(\"RMSE\")\n",
    "        axes[0].set_xticklabels(df_reg.index, rotation=45)\n",
    "\n",
    "        df_reg['R2'].plot(kind='bar', ax=axes[1], title=\"Regression R2 Comparison\", grid=True)\n",
    "        axes[1].set_ylabel(\"R² Score\")\n",
    "        axes[1].set_xticklabels(df_reg.index, rotation=45)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# classification models\n",
    "clf_metrics_df, _ = collect_model_metrics(best_models, X_clf_test, y_clf_test, y_reg_test)\n",
    "plot_metrics(clf_metrics_df, pd.DataFrame())\n",
    "\n",
    "# regression models\n",
    "_, reg_metrics_df = collect_model_metrics(best_reg_models, X_reg_test, y_clf_test, y_reg_test)\n",
    "plot_metrics(pd.DataFrame(), reg_metrics_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### General Takeaways\n",
    "\n",
    "- **Logistic Regression** Offered solid performance and remains a strong baseline. Its simplicity and interpretability make it a reliable model, though its precision is slightly lower than desirable.\n",
    "\n",
    "- **Linear Regression** Was not suitable for this task. The negative R² value indicates it failed to explain the variation in weekly referral counts, reinforcing that this is not a linear prediction problem.\n",
    "\n",
    "- **Neural Networks**  emerged as the most effective model for predicting next-week referrals, achieving the highest F1 score and recall. It is best suited for identifying at risk students, though some false positives remain.\n",
    "\n",
    "- **Random Forest** Underperformed relative to the neural network and logistic regression, with both lower recall and F1 score. It may require more tuning or deeper feature engineering to be competitive.\n",
    "\n",
    "- **DBSCAN** shows potential for uncovering behavioral profiles but may require further feature selection or tuning.\n",
    "---\n",
    "\n",
    "### Recommendations\n",
    "- Prioritize the Neural Network for referral prediction, as it provided the best overall performance. Consider fine-tuning its architecture and training parameters, and possibly augmenting the dataset to further improve accuracy and generalization.\n",
    "\n",
    "- Use Logistic Regression as a strong, interpretable baseline for comparison and quick deployment. It’s a practical choice when simplicity, transparency, or real time inference is important.\n",
    "\n",
    "- Reevaluate the use of Random Forest unless further optimized. Explore hyperparameter tuning or feature selection to enhance its effectiveness if ensemble methods are desired.\n",
    "\n",
    "- Avoid Linear Regression for this task, as it does not capture the complexity of referral behavior patterns and was worse than simply guessing, which is not unusual for this type of data, but still a factor to consider.\n",
    "\n",
    "- Leverage DBSCAN as a tool for unsupervised behavioral segmentation. Clusters may help identify different risk profiles or behavioral subtypes and inform targeted interventions. Consider improving feature selection or testing other clustering methods to refine groupings.\n",
    "\n",
    "- Explore additional models such as Gradient Boosting or XGBoost to balance precision and recall more effectively.\n",
    "\n",
    "- Incorporate temporal features (e.g., days before/after breaks, weekday effects) to enhance model performance and interpretability in the future.\n",
    "\n",
    "- Use model outputs to trigger proactive supports, especially for students repeatedly flagged to reduce the likelihood of future referrals.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
